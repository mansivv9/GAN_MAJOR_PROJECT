{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir /kaggle/working/results\n#!tar -xzvf   ../input/stackgan-birddataset/CUB_200_2011.tgz","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:26.779415Z","iopub.execute_input":"2022-11-10T00:36:26.779766Z","iopub.status.idle":"2022-11-10T00:36:27.762002Z","shell.execute_reply.started":"2022-11-10T00:36:26.779737Z","shell.execute_reply":"2022-11-10T00:36:27.760410Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport pickle\nimport random\nimport time\n\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image\nfrom keras import Input, Model\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\nfrom keras.layers import add\nfrom tensorflow.keras.optimizers import Adam\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:27.764586Z","iopub.execute_input":"2022-11-10T00:36:27.765321Z","iopub.status.idle":"2022-11-10T00:36:34.478011Z","shell.execute_reply.started":"2022-11-10T00:36:27.765283Z","shell.execute_reply":"2022-11-10T00:36:34.476881Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def build_ca_model():\n    \"\"\"\n    Get conditioning augmentation model.\n    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(256)(input_layer)\n    x = LeakyReLU(alpha=0.2)(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.479400Z","iopub.execute_input":"2022-11-10T00:36:34.480438Z","iopub.status.idle":"2022-11-10T00:36:34.486203Z","shell.execute_reply.started":"2022-11-10T00:36:34.480396Z","shell.execute_reply":"2022-11-10T00:36:34.485160Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def build_embedding_compressor_model():\n    \"\"\"\n    Build embedding compressor model\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(128)(input_layer)\n    x = ReLU()(x)\n    model = Model(inputs=[input_layer], outputs=[x])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.489396Z","iopub.execute_input":"2022-11-10T00:36:34.490018Z","iopub.status.idle":"2022-11-10T00:36:34.510852Z","shell.execute_reply.started":"2022-11-10T00:36:34.489983Z","shell.execute_reply":"2022-11-10T00:36:34.509900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_c(x):\n    mean = x[:, :128]\n    log_sigma = x[:, 128:]\n\n    stddev = K.exp(log_sigma)\n    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n    c = stddev * epsilon + mean\n\n    return c","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.512300Z","iopub.execute_input":"2022-11-10T00:36:34.512752Z","iopub.status.idle":"2022-11-10T00:36:34.521867Z","shell.execute_reply.started":"2022-11-10T00:36:34.512694Z","shell.execute_reply":"2022-11-10T00:36:34.520806Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def build_stage1_generator():\n    \"\"\"\n    Builds a generator model used in Stage-I\n    \"\"\"\n    input_layer = Input(shape=(1024,))\n    x = Dense(256)(input_layer)\n    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n\n    c = Lambda(generate_c)(mean_logsigma)\n\n    input_layer2 = Input(shape=(100,))\n\n    gen_input = Concatenate(axis=1)([c, input_layer2])\n\n    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n    x = ReLU()(x)\n\n    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = Activation(activation='tanh')(x)\n\n    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n    return stage1_gen","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.523686Z","iopub.execute_input":"2022-11-10T00:36:34.523979Z","iopub.status.idle":"2022-11-10T00:36:34.537783Z","shell.execute_reply.started":"2022-11-10T00:36:34.523942Z","shell.execute_reply":"2022-11-10T00:36:34.536671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def residual_block(input):\n    \"\"\"\n    Residual block in the generator network\n    \"\"\"\n    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = add([x, input])\n    x = ReLU()(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.539404Z","iopub.execute_input":"2022-11-10T00:36:34.540115Z","iopub.status.idle":"2022-11-10T00:36:34.550143Z","shell.execute_reply.started":"2022-11-10T00:36:34.540077Z","shell.execute_reply":"2022-11-10T00:36:34.549269Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def joint_block(inputs):\n    c = inputs[0]\n    x = inputs[1]\n\n    c = K.expand_dims(c, axis=1)\n    c = K.expand_dims(c, axis=1)\n    c = K.tile(c, [1, 16, 16, 1])\n    return K.concatenate([c, x], axis=3)","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.551891Z","iopub.execute_input":"2022-11-10T00:36:34.552255Z","iopub.status.idle":"2022-11-10T00:36:34.560449Z","shell.execute_reply.started":"2022-11-10T00:36:34.552221Z","shell.execute_reply":"2022-11-10T00:36:34.559231Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def build_stage2_generator():\n    \"\"\"\n    Create Stage-II generator containing the CA Augmentation Network,\n    the image encoder and the generator network\n    \"\"\"\n\n    # 1. CA Augmentation Network\n    input_layer = Input(shape=(1024,))\n    input_lr_images = Input(shape=(64, 64, 3))\n\n    ca = Dense(256)(input_layer)\n    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n    c = Lambda(generate_c)(mean_logsigma)\n\n    # 2. Image Encoder\n    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n    x = ReLU()(x)\n\n    x = ZeroPadding2D(padding=(1, 1))(x)\n    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = ZeroPadding2D(padding=(1, 1))(x)\n    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # 3. Joint\n    c_code = Lambda(joint_block)([c, x])\n\n    x = ZeroPadding2D(padding=(1, 1))(c_code)\n    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    # 4. Residual blocks\n    x = residual_block(x)\n    x = residual_block(x)\n    x = residual_block(x)\n    x = residual_block(x)\n    # 5. Upsampling blocks\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n\n    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n    x = Activation('tanh')(x)\n\n    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.562074Z","iopub.execute_input":"2022-11-10T00:36:34.562567Z","iopub.status.idle":"2022-11-10T00:36:34.579957Z","shell.execute_reply.started":"2022-11-10T00:36:34.562528Z","shell.execute_reply":"2022-11-10T00:36:34.578947Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_stage2_discriminator():\n    \"\"\"\n    Create Stage-II discriminator network\n    \"\"\"\n    input_layer = Input(shape=(256, 256, 3))\n\n    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n\n    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n    x2 = BatchNormalization()(x2)\n    x2 = LeakyReLU(alpha=0.2)(x2)\n\n    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n    x2 = BatchNormalization()(x2)\n    x2 = LeakyReLU(alpha=0.2)(x2)\n    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n    x2 = BatchNormalization()(x2)\n\n    added_x = add([x, x2])\n    added_x = LeakyReLU(alpha=0.2)(added_x)\n\n    input_layer2 = Input(shape=(4, 4, 128))\n\n    merged_input = concatenate([added_x, input_layer2])\n\n    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n    x3 = BatchNormalization()(x3)\n    x3 = LeakyReLU(alpha=0.2)(x3)\n    x3 = Flatten()(x3)\n    x3 = Dense(1)(x3)\n    x3 = Activation('sigmoid')(x3)\n\n    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n    return stage2_dis","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.584146Z","iopub.execute_input":"2022-11-10T00:36:34.584428Z","iopub.status.idle":"2022-11-10T00:36:34.601381Z","shell.execute_reply.started":"2022-11-10T00:36:34.584403Z","shell.execute_reply":"2022-11-10T00:36:34.600337Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def build_adversarial_model(gen_model2, dis_model, gen_model1):\n    \"\"\"\n    Create adversarial model\n    \"\"\"\n    embeddings_input_layer = Input(shape=(1024, ))\n    noise_input_layer = Input(shape=(100, ))\n    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n\n    gen_model1.trainable = False\n    dis_model.trainable = False\n\n    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n    valid = dis_model([hr_images, compressed_embedding_input_layer])\n\n    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.602771Z","iopub.execute_input":"2022-11-10T00:36:34.603290Z","iopub.status.idle":"2022-11-10T00:36:34.614048Z","shell.execute_reply.started":"2022-11-10T00:36:34.603256Z","shell.execute_reply":"2022-11-10T00:36:34.613321Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nDataset loading related methods\n\"\"\"\n\n\ndef load_class_ids(class_info_file_path):\n    \"\"\"\n    Load class ids from class_info.pickle file\n    \"\"\"\n    with open(class_info_file_path, 'rb') as f:\n        class_ids = pickle.load(f, encoding='latin1')\n        return class_ids\n\n\ndef load_embeddings(embeddings_file_path):\n    \"\"\"\n    Function to load embeddings\n    \"\"\"\n    with open(embeddings_file_path, 'rb') as f:\n        embeddings = pickle.load(f, encoding='latin1')\n        embeddings = np.array(embeddings)\n        print('embeddings: ', embeddings.shape)\n    return embeddings\n\n\ndef load_filenames(filenames_file_path):\n    \"\"\"\n    Load filenames.pickle file and return a list of all file names\n    \"\"\"\n    with open(filenames_file_path, 'rb') as f:\n        filenames = pickle.load(f, encoding='latin1')\n    return filenames\ndef load_bounding_boxes(dataset_dir):\n    \"\"\"\n    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\n    \"\"\"\n    # Paths\n    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n\n    # Read bounding_boxes.txt and images.txt file\n    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n                                    delim_whitespace=True, header=None).astype(int)\n    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n\n    # Create a list of file names\n    file_names = df_file_names[1].tolist()\n\n    # Create a dictionary of file_names and bounding boxes\n    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n\n    # Assign a bounding box to the corresponding image\n    for i in range(0, len(file_names)):\n        # Get the bounding box\n        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n        key = file_names[i][:-4]\n        filename_boundingbox_dict[key] = bounding_box\n\n    return filename_boundingbox_dict\n\ndef get_img(img_path, bbox, image_size):\n    \"\"\"\n    Load and resize images\n    \"\"\"\n    img = Image.open(img_path).convert('RGB')\n    width, height = img.size\n    if bbox is not None:\n        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n        y1 = np.maximum(0, center_y - R)\n        y2 = np.minimum(height, center_y + R)\n        x1 = np.maximum(0, center_x - R)\n        x2 = np.minimum(width, center_x + R)\n        img = img.crop([x1, y1, x2, y2])\n    img = img.resize(image_size, PIL.Image.Resampling.BILINEAR)\n    return img\n\n\ndef load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n    filenames = load_filenames(filenames_file_path)\n    class_ids = load_class_ids(class_info_file_path)\n    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n    all_embeddings = load_embeddings(embeddings_file_path)\n    X, y, embeddings = [], [], []\n\n    print(\"All embeddings shape:\", all_embeddings.shape)\n\n    for index, filename in enumerate(filenames):\n        bounding_box = bounding_boxes[filename]\n\n        try:\n            # Load images\n            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n            img = get_img(img_name, bounding_box, image_size)\n\n            all_embeddings1 = all_embeddings[index, :, :]\n\n            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n            embedding = all_embeddings1[embedding_ix, :]\n\n            X.append(np.array(img))\n            y.append(class_ids[index])\n            embeddings.append(embedding)\n        except Exception as e:\n            print(e)\n\n    X = np.array(X)\n    y = np.array(y)\n    embeddings = np.array(embeddings)\n\n    return X, y, embeddings","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.615463Z","iopub.execute_input":"2022-11-10T00:36:34.615986Z","iopub.status.idle":"2022-11-10T00:36:34.635274Z","shell.execute_reply.started":"2022-11-10T00:36:34.615948Z","shell.execute_reply":"2022-11-10T00:36:34.634337Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nLoss functions\n\"\"\"\n\n\ndef KL_loss(y_true, y_pred):\n    mean = y_pred[:, :128]\n    logsigma = y_pred[:, :128]\n    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n    loss = K.mean(loss)\n    return loss\n\n\ndef custom_generator_loss(y_true, y_pred):\n    # Calculate binary cross entropy loss\n    return K.binary_crossentropy(y_true, y_pred)\n\n\ndef write_log(callback, name, loss, batch_no):\n    \"\"\"\n    Write training summary to TensorBoard\n    \"\"\"\n    summary = tf.Summary()\n    summary_value = summary.value.add()\n    summary_value.simple_value = loss\n    summary_value.tag = name\n    callback.writer.add_summary(summary, batch_no)\n    callback.writer.flush()\n\n\ndef save_rgb_img(img, path):\n    \"\"\"\n    Save an rgb image\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n\n    plt.savefig(path)\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:36:34.636617Z","iopub.execute_input":"2022-11-10T00:36:34.637090Z","iopub.status.idle":"2022-11-10T00:36:34.649486Z","shell.execute_reply.started":"2022-11-10T00:36:34.637050Z","shell.execute_reply":"2022-11-10T00:36:34.648440Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    data_dir = \"../input/birds-dataset/birds\"\n    train_dir = data_dir + \"/train\"\n    test_dir = data_dir + \"/test\"\n    hr_image_size = (256, 256)\n    lr_image_size = (64, 64)\n    batch_size = 64\n    z_dim = 100\n    stage1_generator_lr = 0.0002\n    stage1_discriminator_lr = 0.0002\n    stage1_lr_decay_step = 600\n    epochs = 5\n    condition_dim = 128\n\n    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n\n    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n\n    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n\n    cub_dataset_dir = \"../input/stage1500/CUB_200_2011\"\n\n    # Define optimizers\n    dis_optimizer = Adam(learning_rate=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n    gen_optimizer = Adam(learning_rate=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n\n    \"\"\"\n    Load datasets\n    \"\"\"\n    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n                                                            class_info_file_path=class_info_file_path_train,\n                                                            cub_dataset_dir=cub_dataset_dir,\n                                                            embeddings_file_path=embeddings_file_path_train,\n                                                            image_size=(256, 256))\n\n    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n                                                         class_info_file_path=class_info_file_path_test,\n                                                         cub_dataset_dir=cub_dataset_dir,\n                                                         embeddings_file_path=embeddings_file_path_test,\n                                                         image_size=(256, 256))\n\n    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\n                                             class_info_file_path=class_info_file_path_train,\n                                             cub_dataset_dir=cub_dataset_dir,\n                                             embeddings_file_path=embeddings_file_path_train,\n                                             image_size=(64, 64))\n\n    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\n                                           class_info_file_path=class_info_file_path_test,\n                                           cub_dataset_dir=cub_dataset_dir,\n                                           embeddings_file_path=embeddings_file_path_test,\n                                           image_size=(64, 64))\n\n    \"\"\"\n    Build and compile models\n    \"\"\"\n    stage2_dis = build_stage2_discriminator()\n    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n\n    stage1_gen = build_stage1_generator()\n    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\n    stage1_gen.load_weights(\"../input/stage1500/stage1_gen.h5\")\n\n    stage2_gen = build_stage2_generator()\n    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n\n    embedding_compressor_model = build_embedding_compressor_model()\n    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\n    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\n                              optimizer=gen_optimizer, metrics=None)\n\n    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n    tensorboard.set_model(stage2_gen)\n    tensorboard.set_model(stage2_dis)\n\n    # Generate an array containing real and fake values\n    # Apply label smoothing\n    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n\n    discriminator_loss=[]\n    generator_loss=[]\n    for epoch in range(epochs):\n        print(\"========================================\")\n        print(\"Epoch is:\", epoch)\n\n        gen_losses = []\n        dis_losses = []\n\n        # Load data and train model\n        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n        print(\"Number of batches:{}\".format(number_of_batches))\n        for index in range(number_of_batches):\n            print(\"Batch:{}\".format(index+1))\n\n            # Create a noise vector\n            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n\n            # Generate fake images\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            \"\"\"\n            4. Generate compressed embeddings\n            \"\"\"\n            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n\n            \"\"\"\n            5. Train the discriminator model\n            \"\"\"\n            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n                                                      np.reshape(real_labels, (batch_size, 1)))\n            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n                                                      np.reshape(fake_labels, (batch_size, 1)))\n            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n            print(\"d_loss:{}\".format(d_loss))\n\n            \"\"\"\n            Train the adversarial model\n            \"\"\"\n            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n\n            print(\"g_loss:{}\".format(g_loss))\n\n            dis_losses.append(d_loss)\n            gen_losses.append(g_loss)\n\n        \"\"\"\n        Save losses to Tensorboard after each epoch\n        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n        write_log(tensorboard, 'generator_loss', np.mean(gen_losses)[0], epoch)\n        \"\"\"\n\n        # Generate and save images after every 2nd epoch\n        if epoch % 2 == 0:\n            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n            embedding_batch = embeddings_test[0:batch_size]\n\n            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n\n            # Save images\n            for i, img in enumerate(hr_fake_images[:10]):\n                save_rgb_img(img, \"./results/gen_{}_{}.png\".format(epoch, i))\n\n    # Saving the models\n    stage2_gen.save_weights(\"stage2_gen.h5\")\n    stage2_dis.save_weights(\"stage2_dis.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-11-10T01:00:48.322056Z","iopub.execute_input":"2022-11-10T01:00:48.322491Z","iopub.status.idle":"2022-11-10T01:52:35.351307Z","shell.execute_reply.started":"2022-11-10T01:00:48.322447Z","shell.execute_reply":"2022-11-10T01:52:35.350195Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"embeddings:  (8855, 10, 1024)\nAll embeddings shape: (8855, 10, 1024)\nembeddings:  (2933, 10, 1024)\nAll embeddings shape: (2933, 10, 1024)\nembeddings:  (8855, 10, 1024)\nAll embeddings shape: (8855, 10, 1024)\nembeddings:  (2933, 10, 1024)\nAll embeddings shape: (2933, 10, 1024)\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:03:44.656372: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-11-10 01:03:44.656427: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n2022-11-10 01:03:45.312607: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-11-10 01:03:45.312787: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n","output_type":"stream"},{"name":"stdout","text":"========================================\nEpoch is: 0\nNumber of batches:138\nBatch:1\nd_loss:5.626276195049286\ng_loss:[0.7186397314071655, 0.6884473562240601, 0.015096202492713928]\nBatch:2\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:03:55.804249: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:1.6939403712749481\ng_loss:[0.7420984506607056, 0.7067532539367676, 0.01767260581254959]\nBatch:3\nd_loss:2.2095122318714857\ng_loss:[0.7102028131484985, 0.6770089268684387, 0.016596943140029907]\nBatch:4\nd_loss:1.59212163137272\ng_loss:[0.6847087740898132, 0.6565484404563904, 0.014080168679356575]\nBatch:5\nd_loss:1.2899374514818192\ng_loss:[0.678368866443634, 0.6537840366363525, 0.012292420491576195]\nBatch:6\nd_loss:1.1757406815886497\ng_loss:[0.672045111656189, 0.6485428810119629, 0.011751105077564716]\nBatch:7\nd_loss:1.1478984099812806\ng_loss:[0.6636111736297607, 0.6453336477279663, 0.009138766676187515]\nBatch:8\nd_loss:0.986791480332613\ng_loss:[0.6564363837242126, 0.6233506202697754, 0.016542883589863777]\nBatch:9\nd_loss:0.9264954961836338\ng_loss:[0.6571406722068787, 0.6126850843429565, 0.02222779020667076]\nBatch:10\nd_loss:0.8718276252038777\ng_loss:[0.6463335156440735, 0.6197726130485535, 0.013280455023050308]\nBatch:11\nd_loss:0.890007022768259\ng_loss:[0.6236777305603027, 0.6009162664413452, 0.011380724608898163]\nBatch:12\nd_loss:0.887734099291265\ng_loss:[0.6184573769569397, 0.6016417145729065, 0.008407817222177982]\nBatch:13\nd_loss:0.8712443094700575\ng_loss:[0.6262400150299072, 0.6108181476593018, 0.0077109262347221375]\nBatch:14\nd_loss:0.869207919575274\ng_loss:[0.6249196529388428, 0.6147003173828125, 0.005109656136482954]\nBatch:15\nd_loss:0.909639623016119\ng_loss:[0.6255636811256409, 0.6115949749946594, 0.006984348874539137]\nBatch:16\nd_loss:0.8562920736148953\ng_loss:[0.6178171634674072, 0.6055020093917847, 0.006157572381198406]\nBatch:17\nd_loss:0.9344059615395963\ng_loss:[0.6324930787086487, 0.6235414743423462, 0.0044758012518286705]\nBatch:18\nd_loss:0.7971545569598675\ng_loss:[0.6144922971725464, 0.6045160293579102, 0.0049881357699632645]\nBatch:19\nd_loss:0.871266056317836\ng_loss:[0.5783612728118896, 0.5670514106750488, 0.00565494317561388]\nBatch:20\nd_loss:0.8940958119928837\ng_loss:[0.5749622583389282, 0.5663758516311646, 0.004293208941817284]\nBatch:21\nd_loss:0.8149239025078714\ng_loss:[0.5661088228225708, 0.5545855760574341, 0.005761615466326475]\nBatch:22\nd_loss:0.8757668556645513\ng_loss:[0.551267147064209, 0.5438756346702576, 0.0036957478150725365]\nBatch:23\nd_loss:0.7458591405302286\ng_loss:[0.5803780555725098, 0.5717377662658691, 0.00432015024125576]\nBatch:24\nd_loss:0.6914079354610294\ng_loss:[0.5963625907897949, 0.586020827293396, 0.005170871969312429]\nBatch:25\nd_loss:0.7964483872056007\ng_loss:[0.5518298149108887, 0.5413171052932739, 0.005256368778645992]\nBatch:26\nd_loss:0.7445215741172433\ng_loss:[0.5291220545768738, 0.521696925163269, 0.0037125530652701855]\nBatch:27\nd_loss:0.8268166230991483\ng_loss:[0.5086758136749268, 0.5015119314193726, 0.0035819332115352154]\nBatch:28\nd_loss:0.6701379278674722\ng_loss:[0.5153768658638, 0.5039181113243103, 0.005729379132390022]\nBatch:29\nd_loss:0.732572908513248\ng_loss:[0.4986800253391266, 0.4899590313434601, 0.004360493738204241]\nBatch:30\nd_loss:0.7231751930667087\ng_loss:[0.49140360951423645, 0.48616689443588257, 0.0026183617301285267]\nBatch:31\nd_loss:0.6969737422186881\ng_loss:[0.49089866876602173, 0.4845718741416931, 0.003163402434438467]\nBatch:32\nd_loss:0.7123098557349294\ng_loss:[0.4801003634929657, 0.47212135791778564, 0.003989505581557751]\nBatch:33\nd_loss:0.6848711137427017\ng_loss:[0.4750814437866211, 0.46695807576179504, 0.004061679355800152]\nBatch:34\nd_loss:0.6638359972275794\ng_loss:[0.45235341787338257, 0.44470667839050293, 0.0038233769591897726]\nBatch:35\nd_loss:0.7181771211326122\ng_loss:[0.45638561248779297, 0.4498773515224457, 0.0032541370019316673]\nBatch:36\nd_loss:0.6527536315843463\ng_loss:[0.45910438895225525, 0.4525851607322693, 0.0032596131786704063]\nBatch:37\nd_loss:0.7106140423566103\ng_loss:[0.4649795591831207, 0.4588378667831421, 0.0030708452686667442]\nBatch:38\nd_loss:0.7174712866544724\ng_loss:[0.4677400588989258, 0.4609569013118744, 0.0033915736712515354]\nBatch:39\nd_loss:0.7931591980159283\ng_loss:[0.44272559881210327, 0.43654176592826843, 0.00309191457927227]\nBatch:40\nd_loss:0.7779012285172939\ng_loss:[0.42007961869239807, 0.41447919607162476, 0.0028002080507576466]\nBatch:41\nd_loss:0.6689095995388925\ng_loss:[0.4101080894470215, 0.4049408435821533, 0.002583619672805071]\nBatch:42\nd_loss:0.7195329824462533\ng_loss:[0.4009239375591278, 0.3960161805152893, 0.0024538771249353886]\nBatch:43\nd_loss:0.6507733464241028\ng_loss:[0.4191543757915497, 0.40982699394226074, 0.004663695581257343]\nBatch:44\nd_loss:0.7158335010753945\ng_loss:[0.3932149112224579, 0.3858877420425415, 0.0036635822616517544]\nBatch:45\nd_loss:0.6471291936468333\ng_loss:[0.38170287013053894, 0.3733646869659424, 0.004169092979282141]\nBatch:46\nd_loss:0.6878074815613218\ng_loss:[0.37371522188186646, 0.36831408739089966, 0.0027005691081285477]\nBatch:47\nd_loss:0.6594738774001598\ng_loss:[0.38130831718444824, 0.374947726726532, 0.003180289641022682]\nBatch:48\nd_loss:0.707727431319654\ng_loss:[0.39633864164352417, 0.3907359838485718, 0.00280133169144392]\nBatch:49\nd_loss:0.6756543350202264\ng_loss:[0.3838231861591339, 0.37687790393829346, 0.0034726401790976524]\nBatch:50\nd_loss:0.6768018849834334\ng_loss:[0.3658791780471802, 0.36225852370262146, 0.0018103320617228746]\nBatch:51\nd_loss:0.6586048266617581\ng_loss:[0.36405250430107117, 0.35936102271080017, 0.002345747547224164]\nBatch:52\nd_loss:0.676018926082179\ng_loss:[0.3575923442840576, 0.35440152883529663, 0.0015954148257151246]\nBatch:53\nd_loss:0.6501931620296091\ng_loss:[0.35287874937057495, 0.349162757396698, 0.0018579927273094654]\nBatch:54\nd_loss:0.6574277172476286\ng_loss:[0.35111626982688904, 0.34681805968284607, 0.0021490990184247494]\nBatch:55\nd_loss:0.646595723927021\ng_loss:[0.35576528310775757, 0.3516964614391327, 0.0020344117656350136]\nBatch:56\nd_loss:0.6991699405480176\ng_loss:[0.35300347208976746, 0.347743421792984, 0.0026300237514078617]\nBatch:57\nd_loss:0.7046210029220674\ng_loss:[0.36551737785339355, 0.3595309257507324, 0.002993225585669279]\nBatch:58\nd_loss:0.6433878382085823\ng_loss:[0.3624740242958069, 0.35808736085891724, 0.0021933317184448242]\nBatch:59\nd_loss:0.6680181222036481\ng_loss:[0.3469332158565521, 0.34405508637428284, 0.0014390578726306558]\nBatch:60\nd_loss:0.6571885067896801\ng_loss:[0.34001561999320984, 0.3362363576889038, 0.0018896347610279918]\nBatch:61\nd_loss:0.6534286054593395\ng_loss:[0.3333047926425934, 0.33035218715667725, 0.0014763050712645054]\nBatch:62\nd_loss:0.6609996165061602\ng_loss:[0.3312264680862427, 0.32836711406707764, 0.0014296707231551409]\nBatch:63\nd_loss:0.6327424498740584\ng_loss:[0.3307580351829529, 0.32732611894607544, 0.0017159564886242151]\nBatch:64\nd_loss:0.6166778822662309\ng_loss:[0.330290287733078, 0.3265310525894165, 0.001879613264463842]\nBatch:65\nd_loss:0.6805884207133204\ng_loss:[0.3353978097438812, 0.3311711549758911, 0.00211333017796278]\nBatch:66\nd_loss:0.6271614118049911\ng_loss:[0.3304416835308075, 0.3276037871837616, 0.001418942934833467]\nBatch:67\nd_loss:0.6668214059827733\ng_loss:[0.3339495360851288, 0.3313473165035248, 0.0013011132832616568]\nBatch:68\nd_loss:0.6559970632661134\ng_loss:[0.33085668087005615, 0.3279930055141449, 0.0014318409375846386]\nBatch:69\nd_loss:0.6609771434450522\ng_loss:[0.349139928817749, 0.3464694321155548, 0.001335247652605176]\nBatch:70\nd_loss:0.6340281670272816\ng_loss:[0.35434016585350037, 0.35166504979133606, 0.0013375618727877736]\nBatch:71\nd_loss:0.6261332754802424\ng_loss:[0.3604571521282196, 0.35751551389694214, 0.001470818417146802]\nBatch:72\nd_loss:0.651032789144665\ng_loss:[0.37687453627586365, 0.3743380308151245, 0.0012682531960308552]\nBatch:73\nd_loss:0.6214465751545504\ng_loss:[0.3466733992099762, 0.3439715802669525, 0.0013509133132174611]\nBatch:74\nd_loss:0.6532207438722253\ng_loss:[0.4240109324455261, 0.42124342918395996, 0.001383745577186346]\nBatch:75\nd_loss:0.6352887633256614\ng_loss:[0.5856301784515381, 0.5828965902328491, 0.0013667832827195525]\nBatch:76\nd_loss:0.6847954504191875\ng_loss:[0.5644756555557251, 0.5619058609008789, 0.001284886384382844]\nBatch:77\nd_loss:0.6980665475130081\ng_loss:[0.6680290699005127, 0.6653297543525696, 0.0013496705796569586]\nBatch:78\nd_loss:0.9823369006626308\ng_loss:[0.5274804830551147, 0.5247542858123779, 0.0013631104957312346]\nBatch:79\nd_loss:0.7393072992563248\ng_loss:[4.657756805419922, 4.655536651611328, 0.0011100692208856344]\nBatch:80\nd_loss:0.6868690103292465\ng_loss:[0.9592393636703491, 0.9565481543540955, 0.0013456076849251986]\nBatch:81\nd_loss:0.7423909335630015\ng_loss:[0.7414175868034363, 0.7389146685600281, 0.0012514505069702864]\nBatch:82\nd_loss:0.8073303657583892\ng_loss:[0.6002635955810547, 0.5981419682502747, 0.0010608203010633588]\nBatch:83\nd_loss:0.6301324334926903\ng_loss:[0.5445408821105957, 0.5420622229576111, 0.0012393229408189654]\nBatch:84\nd_loss:0.6467117494903505\ng_loss:[0.6227365136146545, 0.6204323768615723, 0.0011520596453920007]\nBatch:85\nd_loss:0.6411502328701317\ng_loss:[0.5390660166740417, 0.5370395183563232, 0.0010132445022463799]\nBatch:86\nd_loss:0.6206766262475867\ng_loss:[0.4776725769042969, 0.47543179988861084, 0.0011203894391655922]\nBatch:87\nd_loss:0.6084118476137519\ng_loss:[0.471391499042511, 0.4686392843723297, 0.0013761119917035103]\nBatch:88\nd_loss:0.7326673390343785\ng_loss:[0.42354387044906616, 0.42058825492858887, 0.001477805315516889]\nBatch:89\nd_loss:0.6723450659774244\ng_loss:[0.4204564690589905, 0.4170506000518799, 0.00170293846167624]\nBatch:90\nd_loss:0.6344298687763512\ng_loss:[0.417781263589859, 0.4147656559944153, 0.0015078071737661958]\nBatch:91\nd_loss:0.6630572127178311\ng_loss:[0.4077807068824768, 0.40537703037261963, 0.0012018383713439107]\nBatch:92\nd_loss:0.6813850516919047\ng_loss:[0.3992210626602173, 0.3955845832824707, 0.0018182360799983144]\nBatch:93\nd_loss:0.6154738734767307\ng_loss:[0.39227452874183655, 0.3886188566684723, 0.0018278374336659908]\nBatch:94\nd_loss:0.6412488848436624\ng_loss:[0.3897577226161957, 0.38660991191864014, 0.001573899295181036]\nBatch:95\nd_loss:0.6304443343542516\ng_loss:[0.3660544455051422, 0.36346396803855896, 0.001295246067456901]\nBatch:96\nd_loss:0.6218951566261239\ng_loss:[0.3618413507938385, 0.35844773054122925, 0.0016968108247965574]\nBatch:97\nd_loss:0.6190917980275117\ng_loss:[0.35435551404953003, 0.3511800169944763, 0.001587752252817154]\nBatch:98\nd_loss:0.6586488503962755\ng_loss:[0.34680598974227905, 0.3440811038017273, 0.0013624441344290972]\nBatch:99\nd_loss:0.6034970030887052\ng_loss:[0.3431813418865204, 0.3400184214115143, 0.0015814588405191898]\nBatch:100\nd_loss:0.5997960385866463\ng_loss:[0.3535950183868408, 0.35081321001052856, 0.0013909083791077137]\nBatch:101\nd_loss:0.6491176820127293\ng_loss:[0.3491895794868469, 0.3471027910709381, 0.0010434016585350037]\nBatch:102\nd_loss:0.626129724259954\ng_loss:[0.3578830659389496, 0.3555793762207031, 0.001151844160631299]\nBatch:103\nd_loss:0.6309452014684211\ng_loss:[0.3494720757007599, 0.34693533182144165, 0.0012683779932558537]\nBatch:104\nd_loss:0.6150053166784346\ng_loss:[0.34731075167655945, 0.34518542885780334, 0.0010626660659909248]\nBatch:105\nd_loss:0.6267392135923728\ng_loss:[0.34316059947013855, 0.3413733243942261, 0.0008936416124925017]\nBatch:106\nd_loss:0.6196455154567957\ng_loss:[0.335430383682251, 0.33361104130744934, 0.0009096686262637377]\nBatch:107\nd_loss:0.6348543593267095\ng_loss:[0.3336726129055023, 0.331080824136734, 0.0012958962470293045]\nBatch:108\nd_loss:0.6123275721365644\ng_loss:[0.34006452560424805, 0.3380531668663025, 0.0010056828614324331]\nBatch:109\nd_loss:0.613581818761304\ng_loss:[0.33398035168647766, 0.33179038763046265, 0.0010949757415801287]\nBatch:110\nd_loss:0.6019267150259111\ng_loss:[0.33244162797927856, 0.3301571309566498, 0.0011422454845160246]\nBatch:111\nd_loss:0.5942728106165305\ng_loss:[0.3297266364097595, 0.3273983597755432, 0.001164132496342063]\nBatch:112\nd_loss:0.6397612981309067\ng_loss:[0.3325299620628357, 0.32993853092193604, 0.0012957088183611631]\nBatch:113\nd_loss:0.6029953544493765\ng_loss:[0.3421650826931, 0.33981090784072876, 0.0011770904529839754]\nBatch:114\nd_loss:0.5792588248150423\ng_loss:[0.3304012417793274, 0.32793593406677246, 0.0012326554860919714]\nBatch:115\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:11:56.133267: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5897918359987671\ng_loss:[0.3290119767189026, 0.3265995979309082, 0.0012061848537996411]\nBatch:116\nd_loss:0.6461186405504122\ng_loss:[0.3292735517024994, 0.32664987444877625, 0.0013118312926962972]\nBatch:117\nd_loss:0.6108307745307684\ng_loss:[0.33258652687072754, 0.330384761095047, 0.0011008777655661106]\nBatch:118\nd_loss:0.5822635974327568\ng_loss:[0.3298192620277405, 0.3276328444480896, 0.001093213097192347]\nBatch:119\nd_loss:0.6096761496010004\ng_loss:[0.328876793384552, 0.32708004117012024, 0.0008983777952380478]\nBatch:120\nd_loss:0.5968909592265845\ng_loss:[0.3292756974697113, 0.32704824209213257, 0.0011137293186038733]\nBatch:121\nd_loss:0.6095337904407643\ng_loss:[0.3283817172050476, 0.3264923095703125, 0.0009447005577385426]\nBatch:122\nd_loss:0.6059735439012002\ng_loss:[0.3274209201335907, 0.3254534602165222, 0.0009837289107963443]\nBatch:123\nd_loss:0.6778487303527072\ng_loss:[0.3279419541358948, 0.32609713077545166, 0.0009224079549312592]\nBatch:124\nd_loss:0.5948011568980291\ng_loss:[0.32722708582878113, 0.32550048828125, 0.0008633028483018279]\nBatch:125\nd_loss:0.584712665877305\ng_loss:[0.32793787121772766, 0.3257366716861725, 0.0011006015120074153]\nBatch:126\nd_loss:0.5946572508546524\ng_loss:[0.32721084356307983, 0.325241357088089, 0.0009847438195720315]\nBatch:127\nd_loss:0.6064099333016202\ng_loss:[0.32752659916877747, 0.3254736661911011, 0.0010264600859954953]\nBatch:128\nd_loss:0.6066659011412412\ng_loss:[0.32887008786201477, 0.3259612023830414, 0.0014544390141963959]\nBatch:129\nd_loss:0.6050959240383236\ng_loss:[0.3286871612071991, 0.32569605112075806, 0.001495549688115716]\nBatch:130\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:13:00.725969: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.6160620240407297\ng_loss:[0.3272407352924347, 0.3253452181816101, 0.0009477597777731717]\nBatch:131\nd_loss:0.6294726294872817\ng_loss:[0.3279156982898712, 0.32559797167778015, 0.0011588663328438997]\nBatch:132\nd_loss:0.5919322016125079\ng_loss:[0.32709547877311707, 0.32523927092552185, 0.0009281068341806531]\nBatch:133\nd_loss:0.6068557447106286\ng_loss:[0.3268699645996094, 0.3251863121986389, 0.0008418314391747117]\nBatch:134\nd_loss:0.5999537286697887\ng_loss:[0.3269194960594177, 0.32514071464538574, 0.0008893838967196643]\nBatch:135\nd_loss:0.621353564580204\ng_loss:[0.3270420730113983, 0.32541772723197937, 0.0008121752762235701]\nBatch:136\nd_loss:0.5879970937530743\ng_loss:[0.3344922363758087, 0.33294612169265747, 0.000773057749029249]\nBatch:137\nd_loss:0.6019705515354872\ng_loss:[0.3983338177204132, 0.39656615257263184, 0.0008838297217153013]\nBatch:138\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:13:35.059146: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5864625558315311\ng_loss:[0.6074032187461853, 0.6056371927261353, 0.0008830117876641452]\n========================================\nEpoch is: 1\nNumber of batches:138\nBatch:1\nd_loss:0.6208326108753681\ng_loss:[0.6637588143348694, 0.662087082862854, 0.0008358523482456803]\nBatch:2\nd_loss:0.6322262707981281\ng_loss:[0.4692589342594147, 0.4672253429889679, 0.001016794121824205]\nBatch:3\nd_loss:0.6503477767109871\ng_loss:[0.5041001439094543, 0.5018811225891113, 0.0011095223017036915]\nBatch:4\nd_loss:0.7529180674464442\ng_loss:[0.3825754225254059, 0.3805910050868988, 0.0009922091849148273]\nBatch:5\nd_loss:0.625715222209692\ng_loss:[0.39864104986190796, 0.39696016907691956, 0.0008404405671171844]\nBatch:6\nd_loss:0.632801660336554\ng_loss:[0.33490073680877686, 0.333231657743454, 0.000834544887766242]\nBatch:7\nd_loss:0.5961015733191743\ng_loss:[0.32683664560317993, 0.32532966136932373, 0.0007534961914643645]\nBatch:8\nd_loss:0.6168000660836697\ng_loss:[1.5994068384170532, 1.596395492553711, 0.0015056850388646126]\nBatch:9\nd_loss:0.7233007624745369\ng_loss:[3.6471428871154785, 3.6432695388793945, 0.001936707179993391]\nBatch:10\nd_loss:0.6668717530556023\ng_loss:[0.8549413681030273, 0.8526163101196289, 0.001162516651675105]\nBatch:11\nd_loss:0.754191940126475\ng_loss:[0.36405935883522034, 0.36226561665534973, 0.0008968740585260093]\nBatch:12\nd_loss:0.6298008598387241\ng_loss:[0.33740121126174927, 0.3358328938484192, 0.0007841563783586025]\nBatch:13\nd_loss:0.6336677906219848\ng_loss:[0.329546719789505, 0.32790571451187134, 0.0008205078775063157]\nBatch:14\nd_loss:0.620893556624651\ng_loss:[0.33580923080444336, 0.33459702134132385, 0.0006061093881726265]\nBatch:15\nd_loss:0.6048933521378785\ng_loss:[0.36582645773887634, 0.36398473381996155, 0.0009208559058606625]\nBatch:16\nd_loss:0.612632297561504\ng_loss:[0.3357197642326355, 0.33399856090545654, 0.0008606077171862125]\nBatch:17\nd_loss:0.6173186720116064\ng_loss:[0.46202000975608826, 0.46034666895866394, 0.0008366667898371816]\nBatch:18\nd_loss:0.6034198003471829\ng_loss:[0.3309679329395294, 0.3295157551765442, 0.0007260862621478736]\nBatch:19\nd_loss:0.644054265444538\ng_loss:[0.3365904986858368, 0.33510881662368774, 0.0007408476667478681]\nBatch:20\nd_loss:0.6226680928375572\ng_loss:[0.3462820053100586, 0.3447881042957306, 0.0007469531847164035]\nBatch:21\nd_loss:0.6025789125123993\ng_loss:[0.3344467282295227, 0.3329131603240967, 0.0007667773170396686]\nBatch:22\nd_loss:0.6334015256506973\ng_loss:[0.35393738746643066, 0.35278746485710144, 0.0005749593256041408]\nBatch:23\nd_loss:0.600734440402448\ng_loss:[0.3437379002571106, 0.34223026037216187, 0.0007538215722888708]\nBatch:24\nd_loss:0.5754510104306974\ng_loss:[0.33815646171569824, 0.33632588386535645, 0.0009152890415862203]\nBatch:25\nd_loss:0.6066855743993074\ng_loss:[0.3336939811706543, 0.3318854570388794, 0.0009042657911777496]\nBatch:26\nd_loss:0.6003336039211717\ng_loss:[0.3274327516555786, 0.32601070404052734, 0.0007110274164006114]\nBatch:27\nd_loss:0.6386049104621634\ng_loss:[0.3303663730621338, 0.3289868235588074, 0.0006897781859152019]\nBatch:28\nd_loss:0.566834504250437\ng_loss:[0.33670487999916077, 0.33477723598480225, 0.00096381816547364]\nBatch:29\nd_loss:0.6047110006111325\ng_loss:[0.33767154812812805, 0.33619460463523865, 0.000738471862860024]\nBatch:30\nd_loss:0.6237626551628637\ng_loss:[0.3698408603668213, 0.3685731887817383, 0.0006338425446301699]\nBatch:31\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:15:47.200926: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5886745341740607\ng_loss:[0.34949707984924316, 0.3478878140449524, 0.0008046386647038162]\nBatch:32\nd_loss:0.5840893931454048\ng_loss:[0.3492295742034912, 0.34715133905410767, 0.0010391173418611288]\nBatch:33\nd_loss:0.5820208771619946\ng_loss:[0.3502952456474304, 0.3485657572746277, 0.0008647454669699073]\nBatch:34\nd_loss:0.5878980327397585\ng_loss:[0.408847838640213, 0.4070899784564972, 0.0008789291023276746]\nBatch:35\nd_loss:0.6177980095962994\ng_loss:[0.3350309133529663, 0.3334306478500366, 0.0008001293172128499]\nBatch:36\nd_loss:0.5770496162112977\ng_loss:[0.37722161412239075, 0.3755980432033539, 0.00081178720574826]\nBatch:37\nd_loss:0.623961103905458\ng_loss:[0.33153513073921204, 0.32992255687713623, 0.0008062849519774318]\nBatch:38\nd_loss:0.5905855971213896\ng_loss:[0.34800729155540466, 0.3463398218154907, 0.0008337278850376606]\nBatch:39\nd_loss:0.5922060572265764\ng_loss:[0.34624698758125305, 0.344574511051178, 0.0008362447842955589]\nBatch:40\nd_loss:0.6344750673742965\ng_loss:[0.3371054530143738, 0.3356136083602905, 0.0007459293119609356]\nBatch:41\nd_loss:0.5799298888305202\ng_loss:[0.32796943187713623, 0.32629159092903137, 0.0008389160502701998]\nBatch:42\nd_loss:0.6057926136563765\ng_loss:[0.3272194564342499, 0.32585859298706055, 0.0006804256699979305]\nBatch:43\nd_loss:0.5666174920042977\ng_loss:[0.35312196612358093, 0.35135191679000854, 0.0008850199519656599]\nBatch:44\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:16:42.123679: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5839918230194598\ng_loss:[0.3567425310611725, 0.35518503189086914, 0.0007787486538290977]\nBatch:45\nd_loss:0.5627919933758676\ng_loss:[0.40369555354118347, 0.401755154132843, 0.0009701928356662393]\nBatch:46\nd_loss:0.5991157795942854\ng_loss:[0.4370078444480896, 0.4355085492134094, 0.0007496539619751275]\nBatch:47\nd_loss:0.5829918381641619\ng_loss:[0.4124957323074341, 0.4106734097003937, 0.0009111676481552422]\nBatch:48\nd_loss:0.6006600591354072\ng_loss:[0.4087192416191101, 0.4070902168750763, 0.0008145120227709413]\nBatch:49\nd_loss:0.5708861164748669\ng_loss:[0.4345526695251465, 0.43270400166511536, 0.0009243306703865528]\nBatch:50\nd_loss:0.5936549907783046\ng_loss:[0.45618054270744324, 0.45498114824295044, 0.0005996974068693817]\nBatch:51\nd_loss:0.5867500270251185\ng_loss:[0.533765971660614, 0.5322747230529785, 0.0007456387393176556]\nBatch:52\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:17:15.182559: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.6187671460211277\ng_loss:[2.535921335220337, 2.534843683242798, 0.0005387937417253852]\nBatch:53\nd_loss:0.6833517677150667\ng_loss:[0.569268524646759, 0.5680461525917053, 0.0006111827096901834]\nBatch:54\nd_loss:0.634086939971894\ng_loss:[0.3267277181148529, 0.3253467082977295, 0.0006905055488459766]\nBatch:55\nd_loss:0.6232128766132519\ng_loss:[1.626961350440979, 1.6255853176116943, 0.0006879912689328194]\nBatch:56\nd_loss:0.6248168684542179\ng_loss:[2.3095085620880127, 2.3079819679260254, 0.0007633084896951914]\nBatch:57\nd_loss:0.6375456992536783\ng_loss:[0.41875407099723816, 0.4168587327003479, 0.0009476658888161182]\nBatch:58\nd_loss:0.6762074142243364\ng_loss:[0.3848034739494324, 0.3833646774291992, 0.0007194011122919619]\nBatch:59\nd_loss:0.6079486995295156\ng_loss:[0.40632882714271545, 0.4053104519844055, 0.0005091925268061459]\nBatch:60\nd_loss:0.6084608485944045\ng_loss:[0.32721927762031555, 0.3259395956993103, 0.0006398363620974123]\nBatch:61\nd_loss:0.6284680927055888\ng_loss:[0.3272879719734192, 0.32622092962265015, 0.0005335138412192464]\nBatch:62\nd_loss:0.6158574915170902\ng_loss:[0.33483999967575073, 0.33376985788345337, 0.000535070663318038]\nBatch:63\nd_loss:0.6231734113534912\ng_loss:[0.3291803002357483, 0.32789695262908936, 0.0006416710093617439]\nBatch:64\nd_loss:0.5893115966755431\ng_loss:[0.3624708354473114, 0.3611769378185272, 0.0006469455547630787]\nBatch:65\nd_loss:0.6017215548781678\ng_loss:[0.3308146893978119, 0.32930120825767517, 0.0007567463908344507]\nBatch:66\nd_loss:0.5913530521356734\ng_loss:[0.3496139943599701, 0.3485654592514038, 0.0005242670886218548]\nBatch:67\nd_loss:0.6053037272431538\ng_loss:[0.456115186214447, 0.455145001411438, 0.0004850942059420049]\nBatch:68\nd_loss:0.612769823288545\ng_loss:[0.5252470374107361, 0.5241656303405762, 0.0005407154676504433]\nBatch:69\nd_loss:0.6758601436158642\ng_loss:[0.449081689119339, 0.44800764322280884, 0.0005370256258174777]\nBatch:70\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:18:30.703592: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5988023124809843\ng_loss:[0.38276663422584534, 0.38170456886291504, 0.000531031284481287]\nBatch:71\nd_loss:0.5991312690312043\ng_loss:[0.3458419740200043, 0.3447115421295166, 0.0005652173422276974]\nBatch:72\nd_loss:0.6080871305894107\ng_loss:[0.3590429425239563, 0.35798293352127075, 0.0005300074117258191]\nBatch:73\nd_loss:0.5771462422562763\ng_loss:[0.39538007974624634, 0.3943278193473816, 0.0005261350888758898]\nBatch:74\nd_loss:0.5732769451860804\ng_loss:[0.32672929763793945, 0.3256509602069855, 0.0005391632439568639]\nBatch:75\nd_loss:0.612823310540989\ng_loss:[0.3577866554260254, 0.35677075386047363, 0.0005079488619230688]\nBatch:76\nd_loss:0.6067601426620968\ng_loss:[0.44844383001327515, 0.447451651096344, 0.0004960954538546503]\nBatch:77\nd_loss:0.6049031761358492\ng_loss:[0.4905003309249878, 0.4894390106201172, 0.0005306573584675789]\nBatch:78\nd_loss:0.5963355946005322\ng_loss:[0.36341649293899536, 0.3623308539390564, 0.0005428242729976773]\nBatch:79\nd_loss:0.5986650100676343\ng_loss:[0.3466276228427887, 0.34572601318359375, 0.0004508097190409899]\nBatch:80\nd_loss:0.5774401662347373\ng_loss:[0.39877110719680786, 0.3977057933807373, 0.0005326494574546814]\nBatch:81\nd_loss:0.5683027415652759\ng_loss:[0.326983779668808, 0.3260010778903961, 0.000491348619107157]\nBatch:82\nd_loss:0.6019329223781824\ng_loss:[0.4575565457344055, 0.45666638016700745, 0.0004450799315236509]\nBatch:83\nd_loss:0.5878471699543297\ng_loss:[1.2323428392410278, 1.231355905532837, 0.0004934599855914712]\nBatch:84\nd_loss:0.6156173008494079\ng_loss:[2.950284957885742, 2.949321985244751, 0.0004814819258172065]\nBatch:85\nd_loss:0.6011679904768243\ng_loss:[1.4975143671035767, 1.496640920639038, 0.00043673743493855]\nBatch:86\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:19:38.449218: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5894401874393225\ng_loss:[1.006413221359253, 1.005448579788208, 0.00048233545385301113]\nBatch:87\nd_loss:0.578320752363652\ng_loss:[0.9133334755897522, 0.91224604845047, 0.0005437022191472352]\nBatch:88\nd_loss:0.656149146379903\ng_loss:[0.9680913686752319, 0.9669012427330017, 0.0005950704216957092]\nBatch:89\nd_loss:0.6823187388945371\ng_loss:[0.8351820111274719, 0.8337739706039429, 0.0007040316122584045]\nBatch:90\nd_loss:0.589693009853363\ng_loss:[0.7564746141433716, 0.7553038597106934, 0.0005853869370184839]\nBatch:91\nd_loss:0.639268075407017\ng_loss:[0.7182962894439697, 0.7173013687133789, 0.0004974603070877492]\nBatch:92\nd_loss:0.6356723862118088\ng_loss:[0.7629658579826355, 0.7615748643875122, 0.0006954919081181288]\nBatch:93\nd_loss:0.6241055521823\ng_loss:[0.6179982423782349, 0.6165474653244019, 0.0007253855583257973]\nBatch:94\nd_loss:0.6052287967031589\ng_loss:[0.5814608335494995, 0.5801950693130493, 0.000632884562946856]\nBatch:95\nd_loss:0.581092292588437\ng_loss:[0.5226279497146606, 0.5215607285499573, 0.0005336236790753901]\nBatch:96\nd_loss:0.5855654076731298\ng_loss:[0.5750182271003723, 0.5736551284790039, 0.0006815355736762285]\nBatch:97\nd_loss:0.5684562971582636\ng_loss:[0.5666187405586243, 0.5653256177902222, 0.0006465509068220854]\nBatch:98\nd_loss:0.6074586400718545\ng_loss:[0.524380624294281, 0.5231797099113464, 0.0006004564929753542]\nBatch:99\nd_loss:0.573736660182476\ng_loss:[0.4591062068939209, 0.45779508352279663, 0.0006555557483807206]\nBatch:100\nd_loss:0.561704624313279\ng_loss:[0.4016323983669281, 0.40045085549354553, 0.0005907773738726974]\nBatch:101\nd_loss:0.5992584750347305\ng_loss:[0.4343295693397522, 0.4333648681640625, 0.0004823489871341735]\nBatch:102\nd_loss:0.5805416751536541\ng_loss:[0.42031151056289673, 0.41932934522628784, 0.0004910875577479601]\nBatch:103\nd_loss:0.6021175462883548\ng_loss:[0.43437954783439636, 0.4333670139312744, 0.0005062597338110209]\nBatch:104\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:20:55.066555: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5845095647819107\ng_loss:[0.5068330764770508, 0.5059041380882263, 0.0004644584550987929]\nBatch:105\nd_loss:0.5939269203663571\ng_loss:[0.42089951038360596, 0.42011547088623047, 0.00039201322942972183]\nBatch:106\nd_loss:0.59260087471921\ng_loss:[0.4787159860134125, 0.47789502143859863, 0.0004104863037355244]\nBatch:107\nd_loss:0.5782123173121363\ng_loss:[0.5000912547111511, 0.4989742040634155, 0.0005585392937064171]\nBatch:108\nd_loss:0.5796768755899393\ng_loss:[0.44721361994743347, 0.4463050067424774, 0.00045431338367052376]\nBatch:109\nd_loss:0.581388870428782\ng_loss:[0.5014222860336304, 0.500470757484436, 0.0004757608112413436]\nBatch:110\nd_loss:0.5872240790340584\ng_loss:[0.4903765618801117, 0.48935467004776, 0.0005109395133331418]\nBatch:111\nd_loss:0.5675454514857847\ng_loss:[0.6562613844871521, 0.6552014946937561, 0.0005299406475387514]\nBatch:112\nd_loss:0.6144313823315315\ng_loss:[0.7096074819564819, 0.708433210849762, 0.0005871267057955265]\nBatch:113\nd_loss:0.5785537878837204\ng_loss:[0.5272042155265808, 0.5261632204055786, 0.0005204862682148814]\nBatch:114\nd_loss:0.5649871710629668\ng_loss:[0.5158426761627197, 0.5147511959075928, 0.0005457330262288451]\nBatch:115\nd_loss:0.5628109539829893\ng_loss:[0.5714272856712341, 0.5703470706939697, 0.000540119013749063]\nBatch:116\nd_loss:0.6235893423145171\ng_loss:[0.7457898259162903, 0.744611382484436, 0.0005892118206247687]\nBatch:117\nd_loss:0.5816123684635386\ng_loss:[0.7151271104812622, 0.714126467704773, 0.0005003270343877375]\nBatch:118\nd_loss:0.5659527652023826\ng_loss:[0.6878007054328918, 0.6867648959159851, 0.0005178956780582666]\nBatch:119\nd_loss:0.573440528838546\ng_loss:[0.7261412143707275, 0.7252780199050903, 0.0004316024133004248]\nBatch:120\nd_loss:0.569581960386131\ng_loss:[0.6738499999046326, 0.67281174659729, 0.000519128458108753]\nBatch:121\nd_loss:0.5845465151505778\ng_loss:[0.6838856339454651, 0.6829543709754944, 0.0004656245873775333]\nBatch:122\nd_loss:0.5800729327474983\ng_loss:[0.6652075052261353, 0.6642419099807739, 0.00048279977636411786]\nBatch:123\nd_loss:0.6246567943162518\ng_loss:[0.658808708190918, 0.6578928232192993, 0.00045794816105626523]\nBatch:124\nd_loss:0.5671556063462049\ng_loss:[0.8307529091835022, 0.8299365639686584, 0.0004081869265064597]\nBatch:125\nd_loss:0.5649256608448923\ng_loss:[0.7851338386535645, 0.7840892672538757, 0.0005222931504249573]\nBatch:126\nd_loss:0.5771289672702551\ng_loss:[0.8188611268997192, 0.8178534507751465, 0.0005038261879235506]\nBatch:127\nd_loss:0.5862631101335865\ng_loss:[0.6672090888023376, 0.6662646532058716, 0.0004722302546724677]\nBatch:128\nd_loss:0.5834357303247089\ng_loss:[0.6244848966598511, 0.6231414675712585, 0.0006717146607115865]\nBatch:129\nd_loss:0.57964792806888\ng_loss:[0.6090309023857117, 0.6078018546104431, 0.0006145170773379505]\nBatch:130\nd_loss:0.5910172845760826\ng_loss:[0.8367449641227722, 0.8358619809150696, 0.00044149899622425437]\nBatch:131\nd_loss:0.6010617814026773\ng_loss:[1.0159227848052979, 1.0149033069610596, 0.0005097361281514168]\nBatch:132\nd_loss:0.580002318136394\ng_loss:[1.2520434856414795, 1.251173973083496, 0.00043475732672959566]\nBatch:133\nd_loss:0.5862693353847135\ng_loss:[0.9411293864250183, 0.9403086304664612, 0.00041037442861124873]\nBatch:134\nd_loss:0.5891105034388602\ng_loss:[0.9439197182655334, 0.9430862069129944, 0.0004167614970356226]\nBatch:135\nd_loss:0.6277077565318905\ng_loss:[0.7401630282402039, 0.7393918633460999, 0.00038557357038371265]\nBatch:136\nd_loss:0.5740732904523611\ng_loss:[0.8264878988265991, 0.8257458209991455, 0.00037104799412190914]\nBatch:137\nd_loss:0.5739205378340557\ng_loss:[0.8528650999069214, 0.8520195484161377, 0.0004227836325298995]\nBatch:138\nd_loss:0.5785744243476074\ng_loss:[0.8161188960075378, 0.8152629137039185, 0.00042797939386218786]\n========================================\nEpoch is: 2\nNumber of batches:138\nBatch:1\nd_loss:0.5887651764205657\ng_loss:[0.7279887795448303, 0.7271610498428345, 0.0004138692165724933]\nBatch:2\nd_loss:0.5895815232361201\ng_loss:[0.7184778451919556, 0.717517077922821, 0.00048036876250989735]\nBatch:3\nd_loss:0.5838761982304277\ng_loss:[0.7458608150482178, 0.7449024319648743, 0.00047919154167175293]\nBatch:4\nd_loss:0.5836235491151456\ng_loss:[0.7074429392814636, 0.7064605951309204, 0.00049118249444291]\nBatch:5\nd_loss:0.5832045555289369\ng_loss:[0.6618731021881104, 0.6610443592071533, 0.000414360489230603]\nBatch:6\nd_loss:0.599512925138697\ng_loss:[0.6901410222053528, 0.689329206943512, 0.0004059076018165797]\nBatch:7\nd_loss:0.5708088306710124\ng_loss:[0.70359206199646, 0.702837347984314, 0.0003773473436012864]\nBatch:8\nd_loss:0.5668233162141405\ng_loss:[0.7671544551849365, 0.7658109068870544, 0.0006717830547131598]\nBatch:9\nd_loss:0.5774330619024113\ng_loss:[0.7949454188346863, 0.7934107780456543, 0.0007673250511288643]\nBatch:10\nd_loss:0.5704690580678289\ng_loss:[0.7599460482597351, 0.7587919235229492, 0.0005770635325461626]\nBatch:11\nd_loss:0.5998177680376102\ng_loss:[0.7360778450965881, 0.7352129220962524, 0.00043245774577371776]\nBatch:12\nd_loss:0.5747300445509609\ng_loss:[0.7567940354347229, 0.7559665441513062, 0.0004137441283091903]\nBatch:13\nd_loss:0.5753319481445942\ng_loss:[0.7191018462181091, 0.7182724475860596, 0.0004147113359067589]\nBatch:14\nd_loss:0.5794882438494824\ng_loss:[0.7362385392189026, 0.735628068447113, 0.0003052493557333946]\nBatch:15\nd_loss:0.5807386365777347\ng_loss:[0.770853579044342, 0.7699276208877563, 0.000462978845462203]\nBatch:16\nd_loss:0.5736924054072006\ng_loss:[0.7922782301902771, 0.7914022207260132, 0.00043801331776194274]\nBatch:17\nd_loss:0.5792417637021572\ng_loss:[0.7819138169288635, 0.7810855507850647, 0.00041414430597797036]\nBatch:18\nd_loss:0.569472097849939\ng_loss:[0.699269711971283, 0.698569655418396, 0.00035001811920665205]\nBatch:19\nd_loss:0.5938054912985535\ng_loss:[0.6925600171089172, 0.6918017864227295, 0.00037912160041742027]\nBatch:20\nd_loss:0.5757729383039987\ng_loss:[0.6453227996826172, 0.644568681716919, 0.000377069809474051]\nBatch:21\nd_loss:0.5785550569999032\ng_loss:[0.5646552443504333, 0.5638390779495239, 0.00040808675112202764]\nBatch:22\nd_loss:0.5999068669043481\ng_loss:[0.6389082670211792, 0.6382848024368286, 0.0003117445157840848]\nBatch:23\nd_loss:0.5741108666907166\ng_loss:[0.6512674689292908, 0.6504541635513306, 0.00040666398126631975]\nBatch:24\nd_loss:0.5609410955894418\ng_loss:[0.6334874629974365, 0.632515549659729, 0.0004859588807448745]\nBatch:25\nd_loss:0.5849261162802577\ng_loss:[0.5403071641921997, 0.5393446683883667, 0.0004812582046724856]\nBatch:26\nd_loss:0.5692512417153921\ng_loss:[0.542159914970398, 0.5414117574691772, 0.00037408797652460635]\nBatch:27\nd_loss:0.5927260375756305\ng_loss:[0.6675580143928528, 0.6668261289596558, 0.0003659480717033148]\nBatch:28\nd_loss:0.5613898425363004\ng_loss:[0.7069826126098633, 0.7059509754180908, 0.0005158130661584437]\nBatch:29\nd_loss:0.5804168917820789\ng_loss:[0.5026447772979736, 0.5018622279167175, 0.0003912871179636568]\nBatch:30\nd_loss:0.5942980337422341\ng_loss:[0.6533238887786865, 0.652625322341919, 0.00034926942316815257]\nBatch:31\nd_loss:0.5779526067635743\ng_loss:[0.6626823544502258, 0.6618424654006958, 0.0004199344839435071]\nBatch:32\nd_loss:0.5697791601996869\ng_loss:[0.590454638004303, 0.5893698334693909, 0.0005424082046374679]\nBatch:33\nd_loss:0.5626830754627008\ng_loss:[0.5925790667533875, 0.5916658639907837, 0.0004566052812151611]\nBatch:34\nd_loss:0.5693501208152156\ng_loss:[0.6277680397033691, 0.6268351078033447, 0.0004664705484174192]\nBatch:35\nd_loss:0.5895623523974791\ng_loss:[0.5711219310760498, 0.5702582597732544, 0.0004318361752666533]\nBatch:36\nd_loss:0.562644488800288\ng_loss:[0.6729015111923218, 0.6720271706581116, 0.0004371718969196081]\nBatch:37\nd_loss:0.5861798218174954\ng_loss:[0.5858703851699829, 0.5849944353103638, 0.000437968410551548]\nBatch:38\nd_loss:0.5799019744672478\ng_loss:[0.6303810477256775, 0.6294836401939392, 0.0004487058031372726]\nBatch:39\nd_loss:0.5735026554393698\ng_loss:[0.6451088786125183, 0.6442059278488159, 0.00045148402568884194]\nBatch:40\nd_loss:0.589585612546216\ng_loss:[0.5213075876235962, 0.5204718112945557, 0.00041788650560192764]\nBatch:41\nd_loss:0.5634948619617717\ng_loss:[0.5540784001350403, 0.5531540513038635, 0.00046218433999456465]\nBatch:42\nd_loss:0.5868285514588933\ng_loss:[0.5267456769943237, 0.5260084867477417, 0.00036859570536762476]\nBatch:43\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:26:20.164982: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5628115821773463\ng_loss:[0.5832912921905518, 0.582394003868103, 0.00044864730443805456]\nBatch:44\nd_loss:0.5723630121719907\ng_loss:[0.6417446136474609, 0.640907883644104, 0.00041837181197479367]\nBatch:45\nd_loss:0.5504929883500154\ng_loss:[0.5830987691879272, 0.5820667743682861, 0.0005160067230463028]\nBatch:46\nd_loss:0.5822990260785446\ng_loss:[0.64457768201828, 0.6437589526176453, 0.00040936836740002036]\nBatch:47\nd_loss:0.5654749065288343\ng_loss:[0.5870199203491211, 0.586043119430542, 0.000488407677039504]\nBatch:48\nd_loss:0.5778915488699568\ng_loss:[0.8202422261238098, 0.8193929195404053, 0.00042465823935344815]\nBatch:49\nd_loss:0.5568502965161315\ng_loss:[0.637283205986023, 0.6363044381141663, 0.000489378406200558]\nBatch:50\nd_loss:0.5795593934808494\ng_loss:[0.637323260307312, 0.6366478204727173, 0.00033773109316825867]\nBatch:51\nd_loss:0.5786176420515403\ng_loss:[0.6235871315002441, 0.6227388978004456, 0.0004241306451149285]\nBatch:52\nd_loss:0.5989640107218293\ng_loss:[0.5624605417251587, 0.5618440508842468, 0.00030825097928754985]\nBatch:53\nd_loss:0.5561687367298873\ng_loss:[0.5563997626304626, 0.5557221174240112, 0.00033881806302815676]\nBatch:54\nd_loss:0.587605527274718\ng_loss:[0.47463610768318176, 0.4738576412200928, 0.0003892284876201302]\nBatch:55\nd_loss:0.5672624683575123\ng_loss:[0.5868334770202637, 0.586066722869873, 0.000383383478038013]\nBatch:56\nd_loss:0.5801689136096684\ng_loss:[0.572878360748291, 0.5720352530479431, 0.00042155900155194104]\nBatch:57\nd_loss:0.5678037132602185\ng_loss:[0.6239616870880127, 0.6229045987129211, 0.0005285396473482251]\nBatch:58\nd_loss:0.5666302821409772\ng_loss:[0.6354474425315857, 0.634640097618103, 0.0004036732716485858]\nBatch:59\nd_loss:0.598794223718869\ng_loss:[1.8947831392288208, 1.8942086696624756, 0.000287229340756312]\nBatch:60\nd_loss:0.5779662672139239\ng_loss:[1.9911417961120605, 1.9904203414916992, 0.00036075658863410354]\nBatch:61\nd_loss:0.5775071939933696\ng_loss:[1.0838738679885864, 1.0832762718200684, 0.00029879211797378957]\nBatch:62\nd_loss:0.5804046783450758\ng_loss:[0.7758334279060364, 0.7752279043197632, 0.00030275480821728706]\nBatch:63\nd_loss:0.5728824317338876\ng_loss:[0.7664364576339722, 0.7657095193862915, 0.0003634749446064234]\nBatch:64\nd_loss:0.5668442638125271\ng_loss:[0.7743664383888245, 0.7736285924911499, 0.0003689216391649097]\nBatch:65\nd_loss:0.5878517201635987\ng_loss:[0.7998257875442505, 0.7989616394042969, 0.0004320804146118462]\nBatch:66\nd_loss:0.5659209479981655\ng_loss:[0.7810108661651611, 0.7804230451583862, 0.00029390258714556694]\nBatch:67\nd_loss:0.5839904253953137\ng_loss:[0.7629538178443909, 0.7624085545539856, 0.0002726298989728093]\nBatch:68\nd_loss:0.5822814915009076\ng_loss:[0.7414670586585999, 0.740862250328064, 0.00030240375781431794]\nBatch:69\nd_loss:0.565335113889887\ng_loss:[0.7074191570281982, 0.7068213224411011, 0.0002989221829921007]\nBatch:70\nd_loss:0.5888036182150245\ng_loss:[0.7163050770759583, 0.7157119512557983, 0.00029656424885615706]\nBatch:71\nd_loss:0.5616471903631464\ng_loss:[0.7371781468391418, 0.7365548610687256, 0.00031163994572125375]\nBatch:72\nd_loss:0.585114230401814\ng_loss:[0.7378512620925903, 0.7372318506240845, 0.0003097000590059906]\nBatch:73\nd_loss:0.566063262966054\ng_loss:[0.7288640141487122, 0.7282483577728271, 0.0003078414301853627]\nBatch:74\nd_loss:0.6141048823483288\ng_loss:[0.7851147055625916, 0.7844833135604858, 0.00031570656574331224]\nBatch:75\nd_loss:0.571024842611223\ng_loss:[0.783798098564148, 0.783204197883606, 0.00029693968826904893]\nBatch:76\nd_loss:0.5890262732027622\ng_loss:[0.6967122554779053, 0.6961231231689453, 0.00029455978074111044]\nBatch:77\nd_loss:0.5675340697343927\ng_loss:[0.7951526045799255, 0.7945489883422852, 0.00030181315378285944]\nBatch:78\nd_loss:0.5820059768011561\ng_loss:[0.6905997395515442, 0.6899714469909668, 0.0003141338238492608]\nBatch:79\nd_loss:0.5760523800563533\ng_loss:[0.7042050957679749, 0.7036814093589783, 0.00026182906003668904]\nBatch:80\nd_loss:0.5733744547842434\ng_loss:[0.6561384201049805, 0.6555217504501343, 0.0003083232440985739]\nBatch:81\nd_loss:0.5570569813935435\ng_loss:[0.6704902648925781, 0.6699035167694092, 0.0002933847426902503]\nBatch:82\nd_loss:0.5985478552829591\ng_loss:[0.625045895576477, 0.6245187520980835, 0.00026356970192864537]\nBatch:83\nd_loss:0.5510316012660041\ng_loss:[0.7208597660064697, 0.7202893495559692, 0.00028520854539237916]\nBatch:84\nd_loss:0.5700958178895235\ng_loss:[0.7745051383972168, 0.7739313840866089, 0.00028687668964266777]\nBatch:85\nd_loss:0.5789899424344185\ng_loss:[0.7745046615600586, 0.7739870548248291, 0.00025881468900479376]\nBatch:86\nd_loss:0.5671771278575761\ng_loss:[0.7422707080841064, 0.7417107224464417, 0.0002799947978928685]\nBatch:87\nd_loss:0.5661293295561336\ng_loss:[0.771028995513916, 0.7704002857208252, 0.00031435186974704266]\nBatch:88\nd_loss:0.6035277959326777\ng_loss:[0.789315402507782, 0.7886081337928772, 0.00035364506766200066]\nBatch:89\nd_loss:0.5607879231624793\ng_loss:[0.7791723012924194, 0.778367280960083, 0.0004025188973173499]\nBatch:90\nd_loss:0.5676488276003511\ng_loss:[0.7138931751251221, 0.7132401466369629, 0.00032650402863509953]\nBatch:91\nd_loss:0.5844729448363069\ng_loss:[0.7275292873382568, 0.7269425392150879, 0.00029336780426092446]\nBatch:92\nd_loss:0.5916523759842676\ng_loss:[0.7593139410018921, 0.7584978342056274, 0.00040805566823109984]\nBatch:93\nd_loss:0.5649396577027801\ng_loss:[0.7117191553115845, 0.7108519077301025, 0.0004336207639425993]\nBatch:94\nd_loss:0.5716907485220872\ng_loss:[0.7332358956336975, 0.7324618101119995, 0.0003870301879942417]\nBatch:95\nd_loss:0.5641147702408489\ng_loss:[0.7016615867614746, 0.7010148763656616, 0.000323349901009351]\nBatch:96\nd_loss:0.5753062776602746\ng_loss:[0.6817605495452881, 0.6809501051902771, 0.0004052235162816942]\nBatch:97\nd_loss:0.5595657137819217\ng_loss:[0.7026267051696777, 0.7018556594848633, 0.00038551626494154334]\nBatch:98\nd_loss:0.5951246209824603\ng_loss:[0.6899650692939758, 0.6892319321632385, 0.00036657924647442997]\nBatch:99\nd_loss:0.5698501676597516\ng_loss:[0.660571277141571, 0.6597772836685181, 0.00039699088665656745]\nBatch:100\nd_loss:0.5502686765503313\ng_loss:[0.6516629457473755, 0.650952935218811, 0.00035500965896062553]\nBatch:101\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:30:27.391633: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5890829138443223\ng_loss:[0.7159265279769897, 0.7153328657150269, 0.0002968288026750088]\nBatch:102\nd_loss:0.5711171799812291\ng_loss:[0.6882607936859131, 0.6876630187034607, 0.0002988820488099009]\nBatch:103\nd_loss:0.5787660142477762\ng_loss:[0.7091758251190186, 0.7085723876953125, 0.00030171737307682633]\nBatch:104\nd_loss:0.5704831471666694\ng_loss:[0.6794567704200745, 0.6788826584815979, 0.0002870672906283289]\nBatch:105\nd_loss:0.5775442460885643\ng_loss:[0.6744261384010315, 0.6739411354064941, 0.0002425162383588031]\nBatch:106\nd_loss:0.5833834211416615\ng_loss:[0.7090137600898743, 0.7085011601448059, 0.00025629845913499594]\nBatch:107\nd_loss:0.5710344378576337\ng_loss:[0.7786770462989807, 0.7779936790466309, 0.0003416956460569054]\nBatch:108\nd_loss:0.577952675211236\ng_loss:[0.7432153224945068, 0.742656409740448, 0.0002794458996504545]\nBatch:109\nd_loss:0.5621688752999034\ng_loss:[0.7830339074134827, 0.782463788986206, 0.0002850644232239574]\nBatch:110\nd_loss:0.5781873502091912\ng_loss:[0.7484775185585022, 0.7478386163711548, 0.0003194586024619639]\nBatch:111\nd_loss:0.5635484521917533\ng_loss:[0.7418668866157532, 0.7411813735961914, 0.0003427706833463162]\nBatch:112\nd_loss:0.5922822527645621\ng_loss:[0.8130024075508118, 0.8122830390930176, 0.00035969348391517997]\nBatch:113\nd_loss:0.5683201221982017\ng_loss:[0.8097574710845947, 0.8091109991073608, 0.0003232491435483098]\nBatch:114\nd_loss:0.5608106494582898\ng_loss:[0.6688650846481323, 0.6681894659996033, 0.0003378051333129406]\nBatch:115\nd_loss:0.5565541662508622\ng_loss:[0.7194876074790955, 0.7187991142272949, 0.00034423419856466353]\nBatch:116\nd_loss:0.5917444854858331\ng_loss:[0.7491852045059204, 0.7484441995620728, 0.0003705003473442048]\nBatch:117\nd_loss:0.5777995164971799\ng_loss:[0.7713689804077148, 0.7707458734512329, 0.00031154713360592723]\nBatch:118\nd_loss:0.5645000262884423\ng_loss:[0.7163405418395996, 0.7156718969345093, 0.0003343162825331092]\nBatch:119\nd_loss:0.5696687824092805\ng_loss:[0.7540117502212524, 0.7534523010253906, 0.0002797225897666067]\nBatch:120\nd_loss:0.5632311720910366\ng_loss:[0.6792680621147156, 0.6786129474639893, 0.00032757146982476115]\nBatch:121\nd_loss:0.5736290942004416\ng_loss:[0.6718999147415161, 0.6712900996208191, 0.00030491623328998685]\nBatch:122\nd_loss:0.5680278443469433\ng_loss:[0.6318430304527283, 0.631206750869751, 0.00031814409885555506]\nBatch:123\nd_loss:0.6284549928823253\ng_loss:[1.0311226844787598, 1.030538558959961, 0.0002920506813097745]\nBatch:124\nd_loss:0.5593189464998432\ng_loss:[0.9010692834854126, 0.9005558490753174, 0.00025671726325526834]\nBatch:125\nd_loss:0.5570272993354592\ng_loss:[0.6345598101615906, 0.6339055895805359, 0.00032711884705349803]\nBatch:126\nd_loss:0.5720659353537485\ng_loss:[0.6548024415969849, 0.6541260480880737, 0.0003381877322681248]\nBatch:127\nd_loss:0.5694976137310732\ng_loss:[0.9171192646026611, 0.9165351986885071, 0.0002920230617746711]\nBatch:128\nd_loss:0.5770624490687624\ng_loss:[0.6907998919487, 0.6899780035018921, 0.0004109388100914657]\nBatch:129\nd_loss:0.5675105744157918\ng_loss:[0.7641488909721375, 0.7633829712867737, 0.00038296784623526037]\nBatch:130\nd_loss:0.5955541715957224\ng_loss:[0.7837498784065247, 0.7832015156745911, 0.00027419388061389327]\nBatch:131\nd_loss:0.580748797787237\ng_loss:[0.8087364435195923, 0.8081111907958984, 0.0003126371593680233]\nBatch:132\nd_loss:0.5732098133594263\ng_loss:[0.7326213121414185, 0.7320756316184998, 0.0002728424733504653]\nBatch:133\nd_loss:0.5769371725000383\ng_loss:[0.78420490026474, 0.7836800813674927, 0.0002624225162435323]\nBatch:134\nd_loss:0.5794705942244036\ng_loss:[0.6784858703613281, 0.6779600381851196, 0.0002629304362926632]\nBatch:135\nd_loss:0.5801536562212277\ng_loss:[0.7564553618431091, 0.755957305431366, 0.00024902616860345006]\nBatch:136\nd_loss:0.5626213373470819\ng_loss:[0.7001743316650391, 0.6997053623199463, 0.00023449893342331052]\nBatch:137\nd_loss:0.5616176042385632\ng_loss:[0.6260227560997009, 0.6254869103431702, 0.00026791420532390475]\nBatch:138\nd_loss:0.5818402308796067\ng_loss:[0.8177713751792908, 0.8172216415405273, 0.0002748772967606783]\n========================================\nEpoch is: 3\nNumber of batches:138\nBatch:1\nd_loss:0.5787828678585356\ng_loss:[0.7338612079620361, 0.7333313226699829, 0.0002649486414156854]\nBatch:2\nd_loss:0.5806868041036068\ng_loss:[0.6478277444839478, 0.6472197771072388, 0.00030399594106711447]\nBatch:3\nd_loss:0.5759349428117275\ng_loss:[0.6857832074165344, 0.685195803642273, 0.0002936963574029505]\nBatch:4\nd_loss:0.574849221590739\ng_loss:[0.6421176195144653, 0.6415180563926697, 0.00029977119993418455]\nBatch:5\nd_loss:0.5764602318449761\ng_loss:[0.644732654094696, 0.6442110538482666, 0.0002608063514344394]\nBatch:6\nd_loss:0.5695733591210228\ng_loss:[0.6256354451179504, 0.6251115798950195, 0.00026192754739895463]\nBatch:7\nd_loss:0.563253035685193\ng_loss:[0.5938295722007751, 0.5933443307876587, 0.00024260803184006363]\nBatch:8\nd_loss:0.5655352996072907\ng_loss:[0.5886085629463196, 0.5877900123596191, 0.0004092625167686492]\nBatch:9\nd_loss:0.5655364618032763\ng_loss:[0.6115740537643433, 0.6106741428375244, 0.0004499630886130035]\nBatch:10\nd_loss:0.5626686691030045\ng_loss:[0.6554253101348877, 0.6546847224235535, 0.00037030517705716193]\nBatch:11\nd_loss:0.5891934721294092\ng_loss:[0.5778547525405884, 0.577315092086792, 0.0002698441094253212]\nBatch:12\nd_loss:0.5669431270616769\ng_loss:[0.6437907218933105, 0.6432333588600159, 0.00027867223252542317]\nBatch:13\nd_loss:0.5654962254238853\ng_loss:[0.6383593678474426, 0.6378105878829956, 0.00027438305551186204]\nBatch:14\nd_loss:0.5684361436105974\ng_loss:[0.8518409132957458, 0.8514478206634521, 0.00019654000061564147]\nBatch:15\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:34:08.600338: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5632887342799222\ng_loss:[0.7909182906150818, 0.7903109788894653, 0.0003036526031792164]\nBatch:16\nd_loss:0.5684349196380936\ng_loss:[0.855756402015686, 0.8551773428916931, 0.00028954289155080914]\nBatch:17\nd_loss:0.5839866040187189\ng_loss:[0.8723422884941101, 0.8718082904815674, 0.00026699656154960394]\nBatch:18\nd_loss:0.6176183084025979\ng_loss:[0.7891943454742432, 0.7887548208236694, 0.0002197638532379642]\nBatch:19\nd_loss:0.5640877754631219\ng_loss:[0.7983313202857971, 0.7978404760360718, 0.00024542975006625056]\nBatch:20\nd_loss:0.5857930761994794\ng_loss:[0.7590150833129883, 0.7585304975509644, 0.00024228656548075378]\nBatch:21\nd_loss:0.5747870392806362\ng_loss:[0.8852043747901917, 0.8846585750579834, 0.00027291104197502136]\nBatch:22\nd_loss:0.5963223872240633\ng_loss:[0.8201863169670105, 0.8197627663612366, 0.00021176206064410508]\nBatch:23\nd_loss:0.5865826978115365\ng_loss:[0.8511244058609009, 0.8506012558937073, 0.0002615764387883246]\nBatch:24\nd_loss:0.5587429271545261\ng_loss:[0.8727695941925049, 0.8721340894699097, 0.00031774499802850187]\nBatch:25\nd_loss:0.5929832788242493\ng_loss:[0.8164193630218506, 0.8157687187194824, 0.00032533277408219874]\nBatch:26\nd_loss:0.5634903246245813\ng_loss:[0.8327373266220093, 0.8322434425354004, 0.0002469327882863581]\nBatch:27\nd_loss:0.5785627943914733\ng_loss:[0.7873777151107788, 0.786889374256134, 0.0002441600663587451]\nBatch:28\nd_loss:0.5676473728381097\ng_loss:[0.8089001774787903, 0.8081896901130676, 0.0003552366979420185]\nBatch:29\nd_loss:0.5903444041032344\ng_loss:[0.8875442147254944, 0.8870115280151367, 0.00026633794186636806]\nBatch:30\nd_loss:0.6049501580419019\ng_loss:[0.9348408579826355, 0.9343588352203369, 0.00024102447787299752]\nBatch:31\nd_loss:0.5702207053734583\ng_loss:[0.830223023891449, 0.829678475856781, 0.00027227395912632346]\nBatch:32\nd_loss:0.5655196465595509\ng_loss:[0.8172181248664856, 0.8165060877799988, 0.0003560099867172539]\nBatch:33\nd_loss:0.5599772916611983\ng_loss:[0.7888235449790955, 0.7882055640220642, 0.0003089919628109783]\nBatch:34\nd_loss:0.5679920864567976\ng_loss:[0.7452785968780518, 0.7446610927581787, 0.0003087505465373397]\nBatch:35\nd_loss:0.5826398584467825\ng_loss:[0.7581600546836853, 0.757584273815155, 0.0002878889790736139]\nBatch:36\nd_loss:0.5659363361555734\ng_loss:[0.7253929376602173, 0.724808931350708, 0.00029200679273344576]\nBatch:37\nd_loss:0.5760103162974701\ng_loss:[0.7000907063484192, 0.6995007395744324, 0.00029499331139959395]\nBatch:38\nd_loss:0.5715061608316319\ng_loss:[0.6842176914215088, 0.6836065053939819, 0.0003055851557292044]\nBatch:39\nd_loss:0.5685316374438116\ng_loss:[0.7088165879249573, 0.7082085013389587, 0.0003040337178390473]\nBatch:40\nd_loss:0.5802626767908805\ng_loss:[0.6716715097427368, 0.6711268424987793, 0.0002723190700635314]\nBatch:41\nd_loss:0.561083055799827\ng_loss:[0.7034993767738342, 0.702880859375, 0.00030926225008443]\nBatch:42\nd_loss:0.5770246227621101\ng_loss:[0.6763835549354553, 0.6758888363838196, 0.00024737254716455936]\nBatch:43\nd_loss:0.5615920884956722\ng_loss:[0.6901273131370544, 0.6895381212234497, 0.00029459260986186564]\nBatch:44\nd_loss:0.5695494715801033\ng_loss:[0.7053463459014893, 0.7047824263572693, 0.0002819460351020098]\nBatch:45\nd_loss:0.5472758968680864\ng_loss:[0.7339046001434326, 0.7332127690315247, 0.0003459064173512161]\nBatch:46\nd_loss:0.5799720630602678\ng_loss:[0.7019875049591064, 0.7014288902282715, 0.0002793218591250479]\nBatch:47\nd_loss:0.5583502313129429\ng_loss:[0.7031161189079285, 0.7024716734886169, 0.0003222199738956988]\nBatch:48\nd_loss:0.5720725550168027\ng_loss:[0.6799506545066833, 0.6793906092643738, 0.00028001543250866234]\nBatch:49\nd_loss:0.5538253606719081\ng_loss:[0.7304545044898987, 0.7297765016555786, 0.00033899990376085043]\nBatch:50\nd_loss:0.5694434653269127\ng_loss:[0.6792539954185486, 0.6787860989570618, 0.00023393859737552702]\nBatch:51\nd_loss:0.5726816378664807\ng_loss:[0.6993566155433655, 0.6987717747688293, 0.00029242419986985624]\nBatch:52\nd_loss:0.5872801287041511\ng_loss:[0.6771954298019409, 0.6767745018005371, 0.00021046228357590735]\nBatch:53\nd_loss:0.5498635438198107\ng_loss:[0.7273415923118591, 0.7268757224082947, 0.00023293436970561743]\nBatch:54\nd_loss:0.5849876583088189\ng_loss:[0.6449852585792542, 0.6444497108459473, 0.00026777974562719464]\nBatch:55\nd_loss:0.561897707193566\ng_loss:[0.7159369587898254, 0.7154097557067871, 0.0002636027056723833]\nBatch:56\nd_loss:0.5673632975085638\ng_loss:[0.7416130304336548, 0.7410221695899963, 0.0002954321098513901]\nBatch:57\nd_loss:0.5691526944792713\ng_loss:[0.7081649303436279, 0.7074283361434937, 0.00036829186137765646]\nBatch:58\nd_loss:0.5623408689043572\ng_loss:[0.6260566115379333, 0.625505805015564, 0.00027541129384189844]\nBatch:59\nd_loss:0.5848882002401297\ng_loss:[0.746544361114502, 0.74614417552948, 0.00020008614228572696]\nBatch:60\nd_loss:0.5718690835783491\ng_loss:[0.7552381753921509, 0.7547340393066406, 0.00025208256556652486]\nBatch:61\nd_loss:0.5752235121326521\ng_loss:[0.7290611863136292, 0.7286523580551147, 0.0002044272405328229]\nBatch:62\nd_loss:0.5735398311062454\ng_loss:[0.6779579520225525, 0.6775435209274292, 0.00020721260807476938]\nBatch:63\nd_loss:0.5609997420524451\ng_loss:[0.6816180944442749, 0.6811181306838989, 0.0002499715774320066]\nBatch:64\nd_loss:0.5616065752692521\ng_loss:[0.8011845946311951, 0.8006733655929565, 0.00025562260998412967]\nBatch:65\nd_loss:0.5742646766229882\ng_loss:[0.84243243932724, 0.841829240322113, 0.0003015909460373223]\nBatch:66\nd_loss:0.5639851414089208\ng_loss:[0.9045559763908386, 0.9041541814804077, 0.00020090476027689874]\nBatch:67\nd_loss:0.5742531394043908\ng_loss:[0.7728983759880066, 0.7725285291671753, 0.00018492244998924434]\nBatch:68\nd_loss:0.577220948995091\ng_loss:[0.7404983639717102, 0.7400802373886108, 0.00020905544806737453]\nBatch:69\nd_loss:0.5686024859842291\ng_loss:[0.7237009406089783, 0.7232962846755981, 0.00020232789393048733]\nBatch:70\nd_loss:0.5754309940220992\ng_loss:[0.6954185366630554, 0.6950196623802185, 0.00019943693769164383]\nBatch:71\nd_loss:0.5599750766577927\ng_loss:[0.7287698984146118, 0.7283473014831543, 0.00021128631487954408]\nBatch:72\nd_loss:0.5766104252807054\ng_loss:[0.6599661707878113, 0.6595466136932373, 0.00020976597443223]\nBatch:73\nd_loss:0.5632265064959938\ng_loss:[0.6398685574531555, 0.6394363641738892, 0.0002161036100005731]\nBatch:74\nd_loss:0.588381595480314\ng_loss:[0.7188377380371094, 0.7183969020843506, 0.0002204234478995204]\nBatch:75\nd_loss:0.5663627163303318\ng_loss:[0.6809588074684143, 0.6805382966995239, 0.0002102616854244843]\nBatch:76\nd_loss:0.5754102079299628\ng_loss:[0.6126829981803894, 0.6122671365737915, 0.00020794550073333085]\nBatch:77\nd_loss:0.5632168579140853\ng_loss:[0.6255632042884827, 0.6251484751701355, 0.00020737414888571948]\nBatch:78\nd_loss:0.5679614350856355\ng_loss:[0.6408659815788269, 0.6404334902763367, 0.0002162316086469218]\nBatch:79\nd_loss:0.5716225606884109\ng_loss:[0.6290499567985535, 0.6286824941635132, 0.00018372345948591828]\nBatch:80\nd_loss:0.5664769417917341\ng_loss:[0.6592593193054199, 0.6588246822357178, 0.0002173163666157052]\nBatch:81\nd_loss:0.5536064670523047\ng_loss:[0.6219465732574463, 0.6215305328369141, 0.0002080338599625975]\nBatch:82\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:38:51.090921: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5877728344421485\ng_loss:[0.6150358319282532, 0.6146615743637085, 0.00018711446318775415]\nBatch:83\nd_loss:0.5479313652394922\ng_loss:[0.6564682126045227, 0.6560639142990112, 0.00020213965035509318]\nBatch:84\nd_loss:0.5629932173033012\ng_loss:[0.6389927864074707, 0.6385868787765503, 0.00020294498244766146]\nBatch:85\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:39:03.395826: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5754415595511091\ng_loss:[0.7021012306213379, 0.7017389535903931, 0.00018113144324161112]\nBatch:86\nd_loss:0.5627457920782035\ng_loss:[0.6620925664901733, 0.6617044806480408, 0.0001940389338415116]\nBatch:87\nd_loss:0.5626835919392761\ng_loss:[0.699490487575531, 0.6990559697151184, 0.0002172540407627821]\nBatch:88\nd_loss:0.5966139950614888\ng_loss:[0.6650933623313904, 0.6645922660827637, 0.00025056206504814327]\nBatch:89\nd_loss:0.5607836936151216\ng_loss:[0.630748450756073, 0.6301796436309814, 0.0002844021946657449]\nBatch:90\nd_loss:0.5625150197170115\ng_loss:[0.6372994184494019, 0.6368461847305298, 0.00022661249386146665]\nBatch:91\nd_loss:0.5805768969403289\ng_loss:[0.6417165994644165, 0.641303300857544, 0.00020665503689087927]\nBatch:92\nd_loss:0.5819570729217958\ng_loss:[0.6689087152481079, 0.6683293581008911, 0.0002896692603826523]\nBatch:93\nd_loss:0.560244659674936\ng_loss:[0.6257630586624146, 0.6251494884490967, 0.0003067733778152615]\nBatch:94\nd_loss:0.5699902915548591\ng_loss:[0.6288126111030579, 0.6282601356506348, 0.0002762458170764148]\nBatch:95\nd_loss:0.5598566488461074\ng_loss:[0.5900134444236755, 0.5895482301712036, 0.00023259638692252338]\nBatch:96\nd_loss:0.5715128923220618\ng_loss:[0.6256123185157776, 0.6250382661819458, 0.00028701918199658394]\nBatch:97\nd_loss:0.5533148779795738\ng_loss:[0.611808717250824, 0.611266553401947, 0.0002710720000322908]\nBatch:98\nd_loss:0.5879861150388024\ng_loss:[0.6149542331695557, 0.614425539970398, 0.00026433661696501076]\nBatch:99\nd_loss:0.5675823437413783\ng_loss:[0.6387295722961426, 0.6381553411483765, 0.0002871053875423968]\nBatch:100\nd_loss:0.5457456223639383\ng_loss:[0.6438176035881042, 0.6433079242706299, 0.0002548409393057227]\nBatch:101\nd_loss:0.5844903527749921\ng_loss:[0.6424108147621155, 0.6419792175292969, 0.0002157894487027079]\nBatch:102\nd_loss:0.5650044245394383\ng_loss:[0.7208516001701355, 0.7204226851463318, 0.0002144521859008819]\nBatch:103\nd_loss:0.5769265848664418\ng_loss:[0.6319495439529419, 0.6315150260925293, 0.00021725310944020748]\nBatch:104\nd_loss:0.5621888205650976\ng_loss:[0.6893755197525024, 0.688957929611206, 0.00020878299255855381]\nBatch:105\nd_loss:0.5692232957298984\ng_loss:[0.6476687788963318, 0.6473174095153809, 0.00017568396287970245]\nBatch:106\nd_loss:0.5780364475156148\ng_loss:[0.63936448097229, 0.6389915347099304, 0.00018646076205186546]\nBatch:107\nd_loss:0.5604326132852293\ng_loss:[0.6724501848220825, 0.6719520688056946, 0.00024905288591980934]\nBatch:108\nd_loss:0.5696835018134152\ng_loss:[0.6595158576965332, 0.6591103076934814, 0.00020278088049963117]\nBatch:109\nd_loss:0.5586070095951072\ng_loss:[0.7068429589271545, 0.7064431309700012, 0.00019992572197224945]\nBatch:110\nd_loss:0.5736274038536067\ng_loss:[0.658279299736023, 0.6578099727630615, 0.00023465443518944085]\nBatch:111\nd_loss:0.5592730811367801\ng_loss:[0.6563580632209778, 0.6558475494384766, 0.0002552455698605627]\nBatch:112\nd_loss:0.5794640063686529\ng_loss:[0.6294107437133789, 0.6288964748382568, 0.0002571275981608778]\nBatch:113\nd_loss:0.564609376117005\ng_loss:[0.6645280122756958, 0.6640560030937195, 0.00023598995176143944]\nBatch:114\nd_loss:0.5590747723836103\ng_loss:[0.6093984246253967, 0.6089019775390625, 0.00024822913110256195]\nBatch:115\nd_loss:0.5517919154444826\ng_loss:[0.5748637914657593, 0.574347972869873, 0.00025791022926568985]\nBatch:116\nd_loss:0.5847655116795067\ng_loss:[0.8225001096725464, 0.8219562768936157, 0.0002719145850278437]\nBatch:117\nd_loss:0.5703653984492121\ng_loss:[0.7816154360771179, 0.7811580896377563, 0.00022866646759212017]\nBatch:118\nd_loss:0.5591229629135341\ng_loss:[0.7478364109992981, 0.7473433017730713, 0.00024654919980093837]\nBatch:119\nd_loss:0.5668367630078137\ng_loss:[0.7335820198059082, 0.7331643104553223, 0.00020886751008220017]\nBatch:120\nd_loss:0.5574741370164702\ng_loss:[0.7367438673973083, 0.7362599968910217, 0.00024192439741455019]\nBatch:121\nd_loss:0.5641123755813169\ng_loss:[0.6471868753433228, 0.6467249393463135, 0.00023095414508134127]\nBatch:122\nd_loss:0.5616439252667078\ng_loss:[0.6745451092720032, 0.6740664839744568, 0.00023931209580041468]\nBatch:123\nd_loss:0.6074373279698193\ng_loss:[0.8951817750930786, 0.8947504758834839, 0.0002156440750695765]\nBatch:124\nd_loss:0.5642121993005276\ng_loss:[0.9868781566619873, 0.9865021705627441, 0.0001879784686025232]\nBatch:125\nd_loss:0.6928199136455078\ng_loss:[5.318376064300537, 5.317904472351074, 0.00023589152260683477]\nBatch:126\nd_loss:0.6503440588712692\ng_loss:[14.453227043151855, 14.4526948928833, 0.00026583700673654675]\nBatch:127\nd_loss:0.7317745412074146\ng_loss:[1.7605359554290771, 1.7592992782592773, 0.0006183247314766049]\nBatch:128\nd_loss:0.6865294463932514\ng_loss:[2.236609935760498, 2.235365867614746, 0.0006220347131602466]\nBatch:129\nd_loss:0.6675338340392045\ng_loss:[1.4134443998336792, 1.4123079776763916, 0.0005682115443050861]\nBatch:130\nd_loss:0.7092533773757168\ng_loss:[0.6582120060920715, 0.6575077772140503, 0.0003521172038745135]\nBatch:131\nd_loss:0.6848202919172763\ng_loss:[0.35463815927505493, 0.3538708984851837, 0.0003836275136563927]\nBatch:132\nd_loss:0.5696855103888083\ng_loss:[0.32919493317604065, 0.3284229636192322, 0.00038598995888605714]\nBatch:133\nd_loss:0.5895022405056807\ng_loss:[0.3751465976238251, 0.3743093013763428, 0.00041865446837618947]\nBatch:134\nd_loss:0.6079462348570814\ng_loss:[0.38926172256469727, 0.38852474093437195, 0.00036849064053967595]\nBatch:135\nd_loss:0.5919920296801138\ng_loss:[0.40852177143096924, 0.40787413716316223, 0.00032381940400227904]\nBatch:136\nd_loss:0.5766735953011448\ng_loss:[0.36204278469085693, 0.3615315854549408, 0.0002556059625931084]\nBatch:137\nd_loss:0.5741536479363276\ng_loss:[0.3408835530281067, 0.3403271436691284, 0.0002781980438157916]\nBatch:138\nd_loss:0.5782846576184966\ng_loss:[0.4267336130142212, 0.42585819959640503, 0.0004377077566459775]\n========================================\nEpoch is: 4\nNumber of batches:138\nBatch:1\nd_loss:0.5934634787263349\ng_loss:[0.38837867975234985, 0.38793736696243286, 0.0002206548524554819]\nBatch:2\nd_loss:0.5967602209129836\ng_loss:[0.41611751914024353, 0.4156018793582916, 0.0002578173007350415]\nBatch:3\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:43:00.766345: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5971349901228677\ng_loss:[0.3342161476612091, 0.33371710777282715, 0.00024951421073637903]\nBatch:4\nd_loss:0.5804985029571981\ng_loss:[0.3870360255241394, 0.3865033984184265, 0.0002663077611941844]\nBatch:5\nd_loss:0.5835755707867065\ng_loss:[0.38435059785842896, 0.3838798403739929, 0.0002353755262447521]\nBatch:6\nd_loss:0.5899950118246124\ng_loss:[0.395396888256073, 0.39480316638946533, 0.00029685956542380154]\nBatch:7\nd_loss:0.5700895864101767\ng_loss:[0.36505326628685, 0.36460167169570923, 0.0002257928135804832]\nBatch:8\nd_loss:0.5685163114112584\ng_loss:[0.37191662192344666, 0.37121397256851196, 0.0003513224655762315]\nBatch:9\nd_loss:0.5759870024962765\ng_loss:[0.5143682956695557, 0.5134532451629639, 0.00045751500874757767]\nBatch:10\nd_loss:0.5690695862167559\ng_loss:[0.43315955996513367, 0.4325081706047058, 0.0003256879863329232]\nBatch:11\nd_loss:0.5847620350623401\ng_loss:[0.6955298781394958, 0.6950621604919434, 0.00023384610540233552]\nBatch:12\nd_loss:0.5850199572050769\ng_loss:[0.42851927876472473, 0.4279947876930237, 0.00026225275360047817]\nBatch:13\nd_loss:0.5797967392209102\ng_loss:[0.4752681851387024, 0.4747360944747925, 0.0002660438185557723]\nBatch:14\nd_loss:0.5817272110343765\ng_loss:[0.4349665343761444, 0.4346197545528412, 0.00017339021724183112]\nBatch:15\nd_loss:0.5860188264559838\ng_loss:[0.5407775044441223, 0.5402399897575378, 0.0002687618543859571]\nBatch:16\nd_loss:0.5819178241363261\ng_loss:[0.3981143534183502, 0.39763903617858887, 0.0002376528427703306]\nBatch:17\nd_loss:0.577691052982118\ng_loss:[0.36633428931236267, 0.3659036159515381, 0.00021532934624701738]\nBatch:18\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:44:03.233886: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5740770777629223\ng_loss:[0.3789283335208893, 0.3785749077796936, 0.00017671473324298859]\nBatch:19\nd_loss:0.5933801890350878\ng_loss:[0.4761650860309601, 0.475770503282547, 0.00019729025370907038]\nBatch:20\nd_loss:0.5774928125611041\ng_loss:[0.42749980092048645, 0.4271126985549927, 0.0001935515319928527]\nBatch:21\nd_loss:0.5689112822874449\ng_loss:[0.39315977692604065, 0.39271292090415955, 0.00022342914598993957]\nBatch:22\nd_loss:0.5904415969271213\ng_loss:[0.36262235045433044, 0.3622743785381317, 0.00017397987539879978]\nBatch:23\nd_loss:0.5699313680961495\ng_loss:[0.4297056496143341, 0.4293026924133301, 0.00020148223848082125]\nBatch:24\nd_loss:0.5671799301926512\ng_loss:[0.4701026976108551, 0.4695874750614166, 0.0002576097322162241]\nBatch:25\nd_loss:0.578241478317068\ng_loss:[0.4695710241794586, 0.4690304100513458, 0.00027030520141124725]\nBatch:26\nd_loss:0.5664457522361772\ng_loss:[0.4273219406604767, 0.4269314110279083, 0.0001952688180608675]\nBatch:27\nd_loss:0.5891467863111757\ng_loss:[0.36643069982528687, 0.36602604389190674, 0.00020232648239471018]\nBatch:28\nd_loss:0.5597110589733347\ng_loss:[0.36334842443466187, 0.36264172196388245, 0.0003533494018483907]\nBatch:29\nd_loss:0.5750505490432261\ng_loss:[0.3852058947086334, 0.3847144842147827, 0.0002457069931551814]\nBatch:30\nd_loss:0.5830828020989429\ng_loss:[0.38008928298950195, 0.379690945148468, 0.00019917322788387537]\nBatch:31\nd_loss:0.5678563850597129\ng_loss:[0.4084376096725464, 0.40800803899765015, 0.0002147817867808044]\nBatch:32\nd_loss:0.5651414318708703\ng_loss:[0.3535369038581848, 0.3529491722583771, 0.00029386550886556506]\nBatch:33\nd_loss:0.558991861573304\ng_loss:[0.35266467928886414, 0.3521146774291992, 0.00027500331634655595]\nBatch:34\nd_loss:0.5659024949272862\ng_loss:[0.40689370036125183, 0.4063698649406433, 0.0002619234728626907]\nBatch:35\nd_loss:0.5817079077969538\ng_loss:[0.36981040239334106, 0.36933577060699463, 0.00023732036061119288]\nBatch:36\nd_loss:0.5633751531131566\ng_loss:[0.4326675534248352, 0.4322064518928528, 0.00023055373458191752]\nBatch:37\nd_loss:0.5865927444538102\ng_loss:[0.38605424761772156, 0.38558220863342285, 0.00023602483270224184]\nBatch:38\nd_loss:0.5756506897741929\ng_loss:[0.46994417905807495, 0.46945589780807495, 0.0002441408287268132]\nBatch:39\nd_loss:0.5684503516531549\ng_loss:[0.36600568890571594, 0.3655245006084442, 0.00024060110445134342]\nBatch:40\nd_loss:0.5860340528306551\ng_loss:[0.4011622965335846, 0.4007398784160614, 0.00021120780729688704]\nBatch:41\nd_loss:0.5660561852273531\ng_loss:[0.6942905783653259, 0.6938008069992065, 0.00024488859344273806]\nBatch:42\nd_loss:0.5891054295789218\ng_loss:[0.3438349664211273, 0.343447208404541, 0.000193880419828929]\nBatch:43\nd_loss:0.5554228800392593\ng_loss:[0.4971977472305298, 0.49671536684036255, 0.00024118818691931665]\nBatch:44\nd_loss:0.5740784218360204\ng_loss:[0.45187807083129883, 0.45142191648483276, 0.00022807662026025355]\nBatch:45\nd_loss:0.5509978524714825\ng_loss:[0.3807448148727417, 0.38018500804901123, 0.00027990693342871964]\nBatch:46\nd_loss:0.5783840941803646\ng_loss:[0.4095856547355652, 0.40913519263267517, 0.00022523195366375148]\nBatch:47\nd_loss:0.559745801743702\ng_loss:[0.38646194338798523, 0.38596537709236145, 0.0002482767158653587]\nBatch:48\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:46:09.085513: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5733449390827445\ng_loss:[0.4049100875854492, 0.4044707119464874, 0.00021968362852931023]\nBatch:49\nd_loss:0.555350742120936\ng_loss:[0.407947301864624, 0.4073740243911743, 0.00028664228739216924]\nBatch:50\nd_loss:0.5668401244620327\ng_loss:[0.48198944330215454, 0.48162150382995605, 0.00018396670930087566]\nBatch:51\nd_loss:0.5765452483901754\ng_loss:[0.38464638590812683, 0.3841712474822998, 0.00023756535665597767]\nBatch:52\nd_loss:0.5844184682646301\ng_loss:[0.3901645839214325, 0.38983091711997986, 0.00016683840658515692]\nBatch:53\nd_loss:0.5566441183764255\ng_loss:[0.44354137778282166, 0.44316476583480835, 0.00018830818589776754]\nBatch:54\nd_loss:0.5839159683091566\ng_loss:[0.456279993057251, 0.45585107803344727, 0.00021445355378091335]\nBatch:55\nd_loss:0.562586264393758\ng_loss:[0.4312295913696289, 0.43080878257751465, 0.000210401980439201]\nBatch:56\nd_loss:0.570517292158911\ng_loss:[0.39919817447662354, 0.39871665835380554, 0.0002407511929050088]\nBatch:57\nd_loss:0.5636471222387627\ng_loss:[0.4217601418495178, 0.42115265130996704, 0.0003037464339286089]\nBatch:58\nd_loss:0.5638155968554202\ng_loss:[0.4349733591079712, 0.4345354437828064, 0.0002189556835219264]\nBatch:59\nd_loss:0.5859872830478707\ng_loss:[0.45004284381866455, 0.4497208297252655, 0.0001610141189303249]\nBatch:60\nd_loss:0.5721368147496833\ng_loss:[0.4310435354709625, 0.43063464760780334, 0.00020444041001610458]\nBatch:61\nd_loss:0.5624629662779626\ng_loss:[0.4317190647125244, 0.4313986301422119, 0.0001602171832928434]\nBatch:62\nd_loss:0.5780681620090036\ng_loss:[0.41573038697242737, 0.4154075086116791, 0.0001614416833035648]\nBatch:63\nd_loss:0.5594033083325485\ng_loss:[0.43075981736183167, 0.43036121129989624, 0.00019930157577618957]\nBatch:64\nd_loss:0.5603525188926142\ng_loss:[0.4477337896823883, 0.44732236862182617, 0.00020570962806232274]\nBatch:65\nd_loss:0.5742906778759789\ng_loss:[0.4508923590183258, 0.4504072070121765, 0.000242581038037315]\nBatch:66\nd_loss:0.5600343719197554\ng_loss:[0.7043740153312683, 0.7040567398071289, 0.00015863252338021994]\nBatch:67\nd_loss:0.581382773918449\ng_loss:[0.3804281949996948, 0.38013869524002075, 0.00014474820636678487]\nBatch:68\nd_loss:0.5750919048441574\ng_loss:[0.4332387447357178, 0.43290942907333374, 0.0001646556775085628]\nBatch:69\nd_loss:0.5643848884647014\ng_loss:[0.37708476185798645, 0.3767701983451843, 0.00015728044672869146]\nBatch:70\nd_loss:0.5835092871711822\ng_loss:[0.3497253358364105, 0.3494111895561218, 0.00015707442071288824]\nBatch:71\nd_loss:0.5647795029508416\ng_loss:[0.34924986958503723, 0.3489183783531189, 0.00016574328765273094]\nBatch:72\nd_loss:0.567226327755634\ng_loss:[0.41051000356674194, 0.41018742322921753, 0.00016128551214933395]\nBatch:73\nd_loss:0.5630875211645616\ng_loss:[0.36547863483428955, 0.36513370275497437, 0.00017246181960217655]\nBatch:74\nd_loss:0.5946491360809887\ng_loss:[0.38866227865219116, 0.3883154094219208, 0.00017343545914627612]\nBatch:75\nd_loss:0.5610562113579363\ng_loss:[0.5350430607795715, 0.5347013473510742, 0.0001708559866528958]\nBatch:76\nd_loss:0.5875463400734589\ng_loss:[0.9887277483940125, 0.9884004592895508, 0.00016363579197786748]\nBatch:77\nd_loss:0.6108990386128426\ng_loss:[2.947535514831543, 2.947206497192383, 0.000164538505487144]\nBatch:78\nd_loss:0.645485719629761\ng_loss:[0.4943808317184448, 0.49402323365211487, 0.0001788021036190912]\nBatch:79\nd_loss:0.5987709357200401\ng_loss:[0.42173823714256287, 0.42140671610832214, 0.00016576454800087959]\nBatch:80\nd_loss:0.5908993729390204\ng_loss:[0.6633853316307068, 0.6630029678344727, 0.000191171420738101]\nBatch:81\nd_loss:0.5888840734842233\ng_loss:[0.3941001296043396, 0.3937499523162842, 0.00017509316967334598]\nBatch:82\nd_loss:0.622892830404453\ng_loss:[0.5391510725021362, 0.5388343334197998, 0.00015836884267628193]\nBatch:83\nd_loss:0.5685735852166545\ng_loss:[0.6224483847618103, 0.6221132874488831, 0.00016755162505432963]\nBatch:84\nd_loss:0.5724584588315338\ng_loss:[0.42113515734672546, 0.42079031467437744, 0.0001724158355500549]\nBatch:85\nd_loss:0.5891962682362646\ng_loss:[0.33807697892189026, 0.33777230978012085, 0.00015233311569318175]\nBatch:86\nd_loss:0.581434419262223\ng_loss:[0.40512073040008545, 0.4047977328300476, 0.00016149706789292395]\nBatch:87\nd_loss:0.562253492360469\ng_loss:[0.4321357309818268, 0.4317808151245117, 0.0001774646807461977]\nBatch:88\nd_loss:0.6013671168111614\ng_loss:[0.3995315730571747, 0.3991195559501648, 0.00020601190044544637]\nBatch:89\nd_loss:0.560402205446735\ng_loss:[0.5704602599143982, 0.5699982047080994, 0.0002310396812390536]\nBatch:90\nd_loss:0.5738243581727147\ng_loss:[0.5331098437309265, 0.5327451229095459, 0.00018236387404613197]\nBatch:91\nd_loss:0.5850423008159851\ng_loss:[0.770178496837616, 0.7698464393615723, 0.00016604205302428454]\nBatch:92\nd_loss:0.5862201399449987\ng_loss:[0.4838799238204956, 0.4834060072898865, 0.00023695870186202228]\nBatch:93\nd_loss:0.5664882328128442\ng_loss:[0.4046327769756317, 0.4041403532028198, 0.00024621165357530117]\nBatch:94\nd_loss:0.5752589644944237\ng_loss:[0.44575634598731995, 0.44531965255737305, 0.00021834715153090656]\nBatch:95\nd_loss:0.5653275342774577\ng_loss:[0.4612809717655182, 0.4609058201313019, 0.0001875705347629264]\nBatch:96\nd_loss:0.5730203114417236\ng_loss:[0.41190019249916077, 0.41144606471061707, 0.0002270603145007044]\nBatch:97\nd_loss:0.5586722246844147\ng_loss:[0.44917044043540955, 0.4487426280975342, 0.00021389879111666232]\nBatch:98\nd_loss:0.5959139640763169\ng_loss:[0.43348413705825806, 0.4330582022666931, 0.00021297376952134073]\nBatch:99\nd_loss:0.5685845780535601\ng_loss:[0.38100919127464294, 0.38054147362709045, 0.00023385581152979285]\nBatch:100\nd_loss:0.5517576467145773\ng_loss:[0.36657920479774475, 0.36616402864456177, 0.0002075817174045369]\nBatch:101\nd_loss:0.5927773858784349\ng_loss:[0.4367639720439911, 0.43641531467437744, 0.00017433175526093692]\nBatch:102\nd_loss:0.56680023298577\ng_loss:[0.558606743812561, 0.558260977268219, 0.0001728959905449301]\nBatch:103\nd_loss:0.5860520807109424\ng_loss:[0.439688116312027, 0.43932977318763733, 0.00017917482182383537]\nBatch:104\nd_loss:0.5656527876217297\ng_loss:[0.7849828004837036, 0.7846443057060242, 0.00016926067473832518]\nBatch:105\nd_loss:0.5783141208521556\ng_loss:[0.44680535793304443, 0.4465188682079315, 0.00014323950745165348]\nBatch:106\nd_loss:0.576974508818239\ng_loss:[0.44740477204322815, 0.4471008777618408, 0.0001519461366115138]\nBatch:107\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:50:18.297577: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5683776785917871\ng_loss:[0.4368623197078705, 0.43645623326301575, 0.00020303814380895346]\nBatch:108\nd_loss:0.574673718525446\ng_loss:[0.3823632597923279, 0.3820343017578125, 0.00016448266978841275]\nBatch:109\nd_loss:0.5660429321942502\ng_loss:[0.3982699513435364, 0.3979540765285492, 0.00015793490456417203]\nBatch:110\nd_loss:0.5727177627268247\ng_loss:[0.4218655824661255, 0.4214719533920288, 0.00019681049161590636]\nBatch:111\nd_loss:0.5659238063235534\ng_loss:[0.3934469521045685, 0.39302486181259155, 0.00021104380721226335]\nBatch:112\nd_loss:0.5847102608531713\ng_loss:[0.5015203952789307, 0.5011109113693237, 0.00020473894255701452]\nBatch:113\nd_loss:0.5673108717273863\ng_loss:[0.5040244460105896, 0.5036372542381287, 0.00019360572332516313]\nBatch:114\nd_loss:0.5613660048838938\ng_loss:[0.4319540560245514, 0.4315411448478699, 0.0002064546279143542]\nBatch:115\nd_loss:0.5529203016776592\ng_loss:[0.6327647566795349, 0.6323380470275879, 0.00021334836492314935]\nBatch:116\nd_loss:0.5855397635932604\ng_loss:[0.43316927552223206, 0.43272751569747925, 0.00022087500838097185]\nBatch:117\nd_loss:0.5715899428723787\ng_loss:[0.560255229473114, 0.5598806142807007, 0.0001873119326774031]\nBatch:118\nd_loss:0.5651650875752239\ng_loss:[0.4841363728046417, 0.4837411344051361, 0.000197615081560798]\nBatch:119\nd_loss:0.5601735625150468\ng_loss:[0.5307148694992065, 0.5303745865821838, 0.00017015135381370783]\nBatch:120\nd_loss:0.5717776982546638\ng_loss:[0.4962240755558014, 0.4958246052265167, 0.0001997405051952228]\nBatch:121\nd_loss:0.5652636652412184\ng_loss:[0.5621276497840881, 0.5617425441741943, 0.0001925380784086883]\nBatch:122\nd_loss:0.5646760101153632\ng_loss:[0.4647147059440613, 0.4643196165561676, 0.0001975372724700719]\nBatch:123\nd_loss:0.5972292901424225\ng_loss:[0.4994727373123169, 0.4991227984428406, 0.0001749682705849409]\nBatch:124\nd_loss:0.5583071546570864\ng_loss:[0.45958003401756287, 0.4592750370502472, 0.00015249144053086638]\nBatch:125\nd_loss:0.5562037370473263\ng_loss:[0.4147627353668213, 0.4143871068954468, 0.0001878144103102386]\nBatch:126\nd_loss:0.569444513005692\ng_loss:[0.5177523493766785, 0.5173231363296509, 0.00021460081916302443]\nBatch:127\nd_loss:0.5698228309483966\ng_loss:[0.49946022033691406, 0.49911269545555115, 0.0001737644342938438]\nBatch:128\nd_loss:0.5763991434214404\ng_loss:[0.39980649948120117, 0.3993304669857025, 0.00023802000214345753]\nBatch:129\n","output_type":"stream"},{"name":"stderr","text":"2022-11-10 01:51:52.462403: W tensorflow/core/data/root_dataset.cc:167] Optimization loop failed: Cancelled: Operation was cancelled\n","output_type":"stream"},{"name":"stdout","text":"d_loss:0.5614160464538145\ng_loss:[0.4830264449119568, 0.4825480878353119, 0.00023918178339954466]\nBatch:130\nd_loss:0.5809313436959656\ng_loss:[0.7919628024101257, 0.7916399240493774, 0.00016143341781571507]\nBatch:131\nd_loss:0.5721297981654061\ng_loss:[0.626599133014679, 0.6262155771255493, 0.00019178011280018836]\nBatch:132\nd_loss:0.5699440433018026\ng_loss:[0.40521374344825745, 0.4048871397972107, 0.00016329826030414551]\nBatch:133\nd_loss:0.566247233771719\ng_loss:[0.4449678361415863, 0.44465380907058716, 0.00015700691437814385]\nBatch:134\nd_loss:0.5757093502907082\ng_loss:[0.4756546914577484, 0.47533950209617615, 0.00015759545203763992]\nBatch:135\nd_loss:0.5715602987911552\ng_loss:[0.6243438720703125, 0.6240422129631042, 0.00015082574100233614]\nBatch:136\nd_loss:0.5710923669539625\ng_loss:[0.5087627172470093, 0.5084782242774963, 0.0001422471832484007]\nBatch:137\nd_loss:0.5587145944800795\ng_loss:[0.47696441411972046, 0.4766416549682617, 0.00016137764032464474]\nBatch:138\nd_loss:0.5724090003095625\ng_loss:[0.6568136811256409, 0.6564753651618958, 0.00016915120068006217]\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls ./results","metadata":{"execution":{"iopub.status.busy":"2022-11-10T01:53:27.476949Z","iopub.execute_input":"2022-11-10T01:53:27.477368Z","iopub.status.idle":"2022-11-10T01:53:28.579451Z","shell.execute_reply.started":"2022-11-10T01:53:27.477332Z","shell.execute_reply":"2022-11-10T01:53:28.578144Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"gen_0_0.png  gen_0_5.png  gen_2_0.png  gen_2_5.png  gen_4_0.png  gen_4_5.png\ngen_0_1.png  gen_0_6.png  gen_2_1.png  gen_2_6.png  gen_4_1.png  gen_4_6.png\ngen_0_2.png  gen_0_7.png  gen_2_2.png  gen_2_7.png  gen_4_2.png  gen_4_7.png\ngen_0_3.png  gen_0_8.png  gen_2_3.png  gen_2_8.png  gen_4_3.png  gen_4_8.png\ngen_0_4.png  gen_0_9.png  gen_2_4.png  gen_2_9.png  gen_4_4.png  gen_4_9.png\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}